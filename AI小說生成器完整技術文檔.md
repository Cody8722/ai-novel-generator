# AI å°èªªè‡ªå‹•ç”Ÿæˆå™¨ - å®Œæ•´æŠ€è¡“æ–‡æª”

> **ç‰ˆæœ¬**: v1.0  
> **æ—¥æœŸ**: 2025-01-03  
> **ä½œè€…**: Cody  
> **æŠ€è¡“æ£§**: Python 3.9+ | çŸ½åŸºæµå‹• API | Qwen2.5

---

## ğŸ“š ç›®éŒ„

- [1. å°ˆæ¡ˆæ¦‚è¿°](#1-å°ˆæ¡ˆæ¦‚è¿°)
- [2. æŠ€è¡“é¸å‹åˆ†æ](#2-æŠ€è¡“é¸å‹åˆ†æ)
- [3. æ ¸å¿ƒæ¶æ§‹è¨­è¨ˆ](#3-æ ¸å¿ƒæ¶æ§‹è¨­è¨ˆ)
- [4. åˆ†å·ç®¡ç†ç³»çµ±](#4-åˆ†å·ç®¡ç†ç³»çµ±)
- [5. ä¸Šä¸‹æ–‡ç®¡ç†æ–¹æ¡ˆ](#5-ä¸Šä¸‹æ–‡ç®¡ç†æ–¹æ¡ˆ)
- [6. JSON è§£æå®¹éŒ¯](#6-json-è§£æå®¹éŒ¯)
- [7. æç¤ºè©ç®¡ç†](#7-æç¤ºè©ç®¡ç†)
- [8. ç”Ÿæˆç›£æ§çµ±è¨ˆ](#8-ç”Ÿæˆç›£æ§çµ±è¨ˆ)
- [9. ç·©å­˜å„ªåŒ–ç³»çµ±](#9-ç·©å­˜å„ªåŒ–ç³»çµ±)
- [10. ä¸€è‡´æ€§æª¢æŸ¥](#10-ä¸€è‡´æ€§æª¢æŸ¥)
- [11. å®Œæ•´ç¨‹å¼ç¢¼](#11-å®Œæ•´ç¨‹å¼ç¢¼)
- [12. ä½¿ç”¨æŒ‡å—](#12-ä½¿ç”¨æŒ‡å—)
- [13. å¸¸è¦‹å•é¡Œ](#13-å¸¸è¦‹å•é¡Œ)

---

## 1. å°ˆæ¡ˆæ¦‚è¿°

### 1.1 å°ˆæ¡ˆèƒŒæ™¯

åœ¨ AI æŠ€è¡“å¿«é€Ÿç™¼å±•çš„ä»Šå¤©ï¼Œå¤§å‹èªè¨€æ¨¡å‹ (LLM) å·²ç¶“å…·å‚™äº†ç›¸ç•¶çš„æ–‡å­¸å‰µä½œèƒ½åŠ›ã€‚æœ¬å°ˆæ¡ˆæ—¨åœ¨é–‹ç™¼ä¸€å€‹åŸºæ–¼åƒå• (Qwen) æ¨¡å‹çš„ **CLI å°èªªç”Ÿæˆå·¥å…·**ï¼Œè®“ä½¿ç”¨è€…èƒ½é€éç°¡å–®çš„æŒ‡ä»¤ä»‹é¢ï¼Œè‡ªå‹•ç”Ÿæˆçµæ§‹å®Œæ•´ã€æƒ…ç¯€é€£è²«çš„å°èªªä½œå“ã€‚

### 1.2 æ ¸å¿ƒç›®æ¨™

- **ä¸»è¦ç›®æ¨™**: å»ºç«‹ä¸€å€‹æ˜“ç”¨çš„å‘½ä»¤åˆ—å°èªªç”Ÿæˆå·¥å…·
- **æŠ€è¡“ç›®æ¨™**: æ•´åˆçŸ½åŸºæµå‹• APIï¼Œå¯¦ç¾ç©©å®šçš„ AI å…§å®¹ç”Ÿæˆ
- **å“è³ªç›®æ¨™**: ç¢ºä¿ç”Ÿæˆå…§å®¹çš„é€£è²«æ€§ã€æ–‡å­¸æ€§å’Œå¯è®€æ€§
- **ä½¿ç”¨ç›®æ¨™**: é™ä½å°èªªå‰µä½œé–€æª»ï¼Œè¼”åŠ©å‰µä½œè€…æ§‹æ€æƒ…ç¯€

### 1.3 ç›®æ¨™ç”¨æˆ¶

- æ¥­é¤˜å°èªªå‰µä½œè€…ï¼ˆå°‹æ‰¾éˆæ„Ÿï¼‰
- ç¶²è·¯æ–‡å­¸ä½œå®¶ï¼ˆå¿«é€Ÿç”¢å‡ºåˆç¨¿ï¼‰
- éŠæˆ²é–‹ç™¼è€…ï¼ˆéœ€è¦åŠ‡æœ¬/ä¸–ç•Œè§€æ–‡æœ¬ï¼‰
- æ–‡å­¸æ„›å¥½è€…ï¼ˆé«”é©— AI å‰µä½œï¼‰

### 1.4 æ ¸å¿ƒç‰¹æ€§

âœ¨ **æ™ºèƒ½åˆ†å·ç³»çµ±**
- æ ¹æ“šåŠ‡æƒ…é‡é»è‡ªå‹•åˆ†å·
- éå›ºå®šç« ç¯€æ•¸ï¼Œéˆæ´»èª¿æ•´
- èªç¾©åŒ–çš„å·çµæ§‹è¨­è¨ˆ

ğŸ§  **é›™å±¤ä¸Šä¸‹æ–‡ç®¡ç†**
- è·¨å·ï¼šå·æ‘˜è¦å£“ç¸®ï¼ˆæ”¯æ´ 100+ ç« ï¼‰
- å·å…§ï¼šRAG èªç¾©æª¢ç´¢ + é‡‘å­—å¡”åˆ†å±¤

ğŸ”’ **å¼·å¤§çš„ä¸€è‡´æ€§ä¿è­‰**
- è§’è‰²æ€§æ ¼è¿½è¹¤
- æ™‚é–“ç·šæª¢æŸ¥
- è¨­å®šä¸€è‡´æ€§é©—è­‰
- åŠ‡æƒ…é‚è¼¯æª¢æŸ¥

ğŸ“Š **å…¨é¢ç›£æ§çµ±è¨ˆ**
- å³æ™‚é€²åº¦é¡¯ç¤º
- æˆæœ¬è¿½è¹¤
- å“è³ªè©•ä¼°
- è©³ç´°å ±å‘Šç”Ÿæˆ

---

## 2. æŠ€è¡“é¸å‹åˆ†æ

### 2.1 ç‚ºä½•é¸æ“‡ CLI è€Œé GUIï¼Ÿ

#### å„ªå‹¢

1. **é–‹ç™¼æ•ˆç‡é«˜**: å°ˆæ³¨æ ¸å¿ƒé‚è¼¯ï¼Œç„¡éœ€è™•ç† UI æ¡†æ¶
2. **è³‡æºæ¶ˆè€—ä½**: é©åˆåœ¨å„ç¨®ç’°å¢ƒé‹è¡Œï¼ˆåŒ…æ‹¬ä¼ºæœå™¨ï¼‰
3. **è‡ªå‹•åŒ–å‹å–„**: æ˜“æ–¼æ•´åˆåˆ°å…¶ä»–å·¥ä½œæµç¨‹
4. **é©åˆæŠ€è¡“ç”¨æˆ¶**: ç›®æ¨™ç”¨æˆ¶ç¾¤é«”ç†Ÿæ‚‰å‘½ä»¤åˆ—æ“ä½œ

#### å¾ŒçºŒæ“´å±•æ€§

```
CLI ä½œç‚ºæ ¸å¿ƒå¼•æ“
    â†“
æœªä¾†å¯åŒ…è£æˆ Web ä»‹é¢
    â†“
æˆ–æä¾› Python æ¨¡çµ„ä¾›å…¶ä»–ç¨‹å¼å‘¼å«
```

### 2.2 API vs æœ¬åœ°æ¨¡å‹å°æ¯”

| è€ƒé‡å› ç´  | çŸ½åŸºæµå‹• API | æœ¬åœ° Ollama |
|---------|------------|-----------|
| **éƒ¨ç½²é›£åº¦** | â­ (åƒ…éœ€ API Key) | â­â­â­ (éœ€ä¸‹è¼‰æ¨¡å‹) |
| **é‹è¡Œé€Ÿåº¦** | â­â­â­â­ (é›²ç«¯ GPU) | â­â­ (è¦–ç¡¬é«”è€Œå®š) |
| **æˆæœ¬** | æŒ‰é‡è¨ˆè²» (æ¥µä½) | å…è²»ä½†éœ€ç¡¬é«” |
| **å“è³ª** | â­â­â­â­ (å¯é¸å¤§æ¨¡å‹) | â­â­â­ (å—é™æœ¬åœ°è³‡æº) |
| **éš±ç§æ€§** | â­â­ (æ•¸æ“šä¸Šå‚³) | â­â­â­â­â­ (å®Œå…¨æœ¬åœ°) |
| **ç¶²è·¯ä¾è³´** | å¿…é ˆé€£ç¶² | ç„¡éœ€ç¶²è·¯ |

#### æ±ºç­–

æ¡ç”¨ **çŸ½åŸºæµå‹• API**ï¼ŒåŸå› ï¼š
1. é–‹ç™¼éšæ®µå¿«é€Ÿè¿­ä»£
2. æˆæœ¬æ¥µä½ï¼ˆæ¸¬è©¦éšæ®µ <Â¥1ï¼‰
3. å¯éš¨æ™‚åˆ‡æ›ä¸åŒè¦æ¨¡æ¨¡å‹
4. æœªä¾†å¯å¢åŠ æœ¬åœ°æ¨¡å‹ä½œç‚ºå‚™é¸æ–¹æ¡ˆ

### 2.3 åƒå•æ¨¡å‹é¸æ“‡

#### å¯ç”¨æ¨¡å‹æ¢¯åº¦

```
Qwen2.5-7B-Instruct   â† èµ·æ­¥é¸æ“‡ (å¹³è¡¡é€Ÿåº¦/å“è³ª)
    â†“ 
Qwen2.5-14B-Instruct  â† å“è³ªæå‡
    â†“
Qwen2.5-32B-Instruct  â† å°ˆæ¥­å‰µä½œ
    â†“
Qwen2.5-72B-Instruct  â† æ——è‰¦ç´š (å‡ºç‰ˆç´š)
```

#### æ¨è–¦ç­–ç•¥

- **é–‹ç™¼æ¸¬è©¦**: 7B æ¨¡å‹ï¼ˆçœéŒ¢ï¼‰
- **æ­£å¼å‰µä½œ**: 14B-32Bï¼ˆæ€§åƒ¹æ¯”æœ€ä½³ï¼‰
- **ç²¾å“ç”¢å‡º**: 72Bï¼ˆé‡è¦ä½œå“ï¼‰

#### ç‚ºä½•é¸é€šç”¨ç‰ˆè€Œé Coder ç‰ˆï¼Ÿ

| é …ç›® | Instruct (é€šç”¨ç‰ˆ) | Coder (ç¨‹å¼ç‰ˆ) |
|------|----------|-------|
| å°èªªç”Ÿæˆ | â­â­â­â­â­ | â­â­ |
| ç¨‹å¼é–‹ç™¼ | â­â­â­ | â­â­â­â­â­ |
| æ–‡å­¸æ€§ | æ›´è±å¯Œç´°è†© | ååŠŸèƒ½æ€§ |
| å°è©±è‡ªç„¶åº¦ | æ›´æµæš¢ | è¼ƒç”Ÿç¡¬ |
| å‰µæ„ç™¼æƒ³ | æ›´å¥½ | é‚è¼¯å°å‘ |

**çµè«–**: å°èªªå‰µä½œå¿…é ˆä½¿ç”¨ **Instruct é€šç”¨ç‰ˆ**

---

## 3. æ ¸å¿ƒæ¶æ§‹è¨­è¨ˆ

### 3.1 æ•´é«”æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ä½¿ç”¨è€…å‘½ä»¤åˆ—ä»‹é¢               â”‚
â”‚   (è¼¸å…¥éœ€æ±‚ã€æŸ¥çœ‹é€²åº¦ã€æ§åˆ¶æµç¨‹)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         NovelGenerator æ ¸å¿ƒé¡åˆ¥          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ API é€šè¨Šå±¤                         â”‚ â”‚
â”‚  â”‚ - è«‹æ±‚ç®¡ç†                         â”‚ â”‚
â”‚  â”‚ - éŒ¯èª¤è™•ç†                         â”‚ â”‚
â”‚  â”‚ - é‡è©¦æ©Ÿåˆ¶                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ å…§å®¹ç”Ÿæˆå±¤                         â”‚ â”‚
â”‚  â”‚ - å¤§ç¶±ç”Ÿæˆ                         â”‚ â”‚
â”‚  â”‚ - ç« ç¯€ç”Ÿæˆ                         â”‚ â”‚
â”‚  â”‚ - ä¸Šä¸‹æ–‡ç®¡ç†                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ å°ˆæ¡ˆç®¡ç†å±¤                         â”‚ â”‚
â”‚  â”‚ - æª”æ¡ˆçµ„ç¹”                         â”‚ â”‚
â”‚  â”‚ - å…ƒæ•¸æ“šç®¡ç†                       â”‚ â”‚
â”‚  â”‚ - ç‰ˆæœ¬æ§åˆ¶                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          çŸ½åŸºæµå‹• API æœå‹™               â”‚
â”‚      (Qwen2.5 æ¨¡å‹æ¨ç†)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æœ¬åœ°æª”æ¡ˆç³»çµ±                   â”‚
â”‚  novel_project_YYYYMMDD_HHMMSS/         â”‚
â”‚  â”œâ”€â”€ metadata.json                      â”‚
â”‚  â”œâ”€â”€ outline.txt                        â”‚
â”‚  â”œâ”€â”€ chapter_01.txt                     â”‚
â”‚  â”œâ”€â”€ chapter_02.txt                     â”‚
â”‚  â””â”€â”€ full_novel.txt                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 è³‡æ–™æµç¨‹

**å°èªªç”Ÿæˆå®Œæ•´æµç¨‹:**

```
Step 1: ä½¿ç”¨è€…è¼¸å…¥åŸºæœ¬è³‡è¨Š
    â†“
    æ¨™é¡Œã€é¡å‹ã€ä¸»é¡Œã€è§’è‰² â†’ metadata.json

Step 2: ç”Ÿæˆæ•…äº‹å¤§ç¶± + åˆ†å·è¦åŠƒ
    â†“
    è¼¸å…¥è³‡è¨Š â†’ AI â†’ åˆ†å·çµæ§‹ + å…¨å±€å¤§ç¶± â†’ outline.txt
    
Step 3: ç‚ºæ¯å·ç”Ÿæˆè©³ç´°å¤§ç¶±
    â†“
    å·è³‡è¨Š + å…¨å±€å¤§ç¶± â†’ AI â†’ å·å¤§ç¶±
    
Step 4: ç« ç¯€é€ä¸€ç”Ÿæˆ
    â†“
    Loop for each chapter:
        ä¸Šä¸‹æ–‡(é›™å±¤æ¶æ§‹) 
            â†’ API 
            â†’ chapter_N.txt
            â†’ æ›´æ–°è¿½è¹¤ç³»çµ±
    
Step 5: å·å®Œæˆæ™‚ç”Ÿæˆæ‘˜è¦
    â†“
    åˆä½µæœ¬å·ç« ç¯€ â†’ AI â†’ å·æ‘˜è¦ â†’ å£“ç¸®å­˜å„²
    
Step 6: å…¨æ›¸å®Œæˆå¾Œåˆä½µ
    â†“
    åˆä½µæ‰€æœ‰ç« ç¯€ â†’ full_novel.txt
```

### 3.3 æª”æ¡ˆçµæ§‹è¨­è¨ˆ

```
novel_æ˜Ÿéš›é‚Šç·£_20250103_143000/
â”œâ”€â”€ metadata.json              # å°ˆæ¡ˆè¨­å®š
â”œâ”€â”€ outline.txt                # å…¨å±€å¤§ç¶±
â”œâ”€â”€ volume_plan.json           # åˆ†å·è¦åŠƒ
â”‚
â”œâ”€â”€ volumes/                   # å·è³‡æ–™å¤¾
â”‚   â”œâ”€â”€ volume_01/
â”‚   â”‚   â”œâ”€â”€ outline.txt        # æœ¬å·å¤§ç¶±
â”‚   â”‚   â”œâ”€â”€ summary.txt        # æœ¬å·æ‘˜è¦
â”‚   â”‚   â”œâ”€â”€ chapter_01.txt
â”‚   â”‚   â”œâ”€â”€ chapter_02.txt
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ volume_02/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ cache/                     # ç·©å­˜è³‡æ–™
â”‚   â”œâ”€â”€ chapter_summaries.json
â”‚   â”œâ”€â”€ character_states.json
â”‚   â””â”€â”€ embeddings/
â”‚
â”œâ”€â”€ reports/                   # çµ±è¨ˆå ±å‘Š
â”‚   â”œâ”€â”€ generation_log.json
â”‚   â””â”€â”€ statistics.png
â”‚
â””â”€â”€ full_novel.txt            # å®Œæ•´å°èªª
```

**ç‚ºä½•é€™æ¨£è¨­è¨ˆï¼Ÿ**
1. **æ¸…æ™°çš„çµæ§‹** â†’ ä¸€çœ¼çœ‹å‡ºå…§å®¹
2. **æŒ‰å·çµ„ç¹”** â†’ ç¬¦åˆå°èªªçµæ§‹
3. **åˆ†é›¢ç·©å­˜** â†’ ä¸æ±¡æŸ“ä¸»è¦å…§å®¹
4. **è©³ç´°è¨˜éŒ„** â†’ æ–¹ä¾¿é™¤éŒ¯å’Œåˆ†æ

---

## 4. åˆ†å·ç®¡ç†ç³»çµ±

### 4.1 ç‚ºä½•éœ€è¦åˆ†å·ï¼Ÿ

å‚³çµ±çš„æŒ‰å›ºå®šç« ç¯€æ•¸åˆ†å·ï¼ˆå¦‚æ¯ 20 ç« ä¸€å·ï¼‰å­˜åœ¨å•é¡Œï¼š

âŒ **å•é¡Œ**:
- æ©Ÿæ¢°å¼åˆ‡å‰²ï¼Œç„¡è¦–åŠ‡æƒ…çµæ§‹
- å¯èƒ½åœ¨é«˜æ½®è™•æ–·é–‹
- ç„¡æ³•é©æ‡‰ä¸åŒç¯€å¥çš„æ•…äº‹

âœ… **èªç¾©åˆ†å·çš„å„ªå‹¢**:
- æ ¹æ“šåŠ‡æƒ…é‡é»è‡ªç„¶åˆ†æ®µ
- æ¯å·æœ‰æ˜ç¢ºçš„æˆ²åŠ‡ç›®æ¨™
- ç¬¦åˆå‚³çµ±å°èªªçµæ§‹

### 4.2 èªç¾©åˆ†å·åŸç†

```
çœŸå¯¦å°èªªçš„åˆ†å·é‚è¼¯ï¼š

ç¬¬ä¸€å·ã€Œåˆå…¥æ±Ÿæ¹–ã€(8ç« )
â””â”€ ä¸»ç·šï¼šä¸»è§’å¾å°æ‘èŠåˆ°æ­¦æ—å¤§æœƒ
â””â”€ å ´æ™¯ï¼šå°æ‘â†’å®¢æ£§â†’é’åŸâ†’æ­¦æ—å¤§æœƒ
â””â”€ é‡é»ï¼šæˆé•·ã€åˆæ¬¡è¦‹è­˜æ±Ÿæ¹–éšªæƒ¡
â””â”€ ç›®æ¨™ï¼šæ±ºå®šè¸å…¥æ±Ÿæ¹–

ç¬¬äºŒå·ã€Œåé–€ä¹‹çˆ­ã€(15ç« )  
â””â”€ ä¸»ç·šï¼šæ²å…¥åé–€æ­£é‚ªä¹‹çˆ­
â””â”€ å ´æ™¯ï¼šå„å¤§é–€æ´¾ã€ç§˜å¢ƒ
â””â”€ é‡é»ï¼šç«‹å ´é¸æ“‡ã€å¯¦åŠ›æå‡
â””â”€ ç›®æ¨™ï¼šåœ¨æ­£é‚ªä¹‹é–“æ‰¾åˆ°è‡ªå·±çš„é“è·¯

ç¬¬ä¸‰å·ã€Œé­”æ•™å´›èµ·ã€(12ç« )
â””â”€ ä¸»ç·šï¼šå°æŠ—é­”æ•™é™°è¬€
â””â”€ å ´æ™¯ï¼šé­”æ•™ç¸½å£‡ã€æ±ºæˆ°åœ°
â””â”€ é‡é»ï¼šæœ€çµ‚å°æ±ºã€æ­é–‹èº«ä¸–ä¹‹è¬
â””â”€ ç›®æ¨™ï¼šæ‹¯æ•‘æ­¦æ—ï¼Œå®Œæˆæˆé•·
```

### 4.3 åˆ†å·è¦åŠƒæµç¨‹

#### æ–¹å¼ä¸€ï¼šAI è‡ªå‹•å»ºè­°

```python
# è¼¸å…¥
title = "æ˜Ÿéš›é‚Šç·£"
genre = "å¤ªç©ºæ­ŒåŠ‡ç§‘å¹»"
theme = "äººé¡æ–‡æ˜çš„å­˜çºŒèˆ‡è›»è®Š"
total_chapters = 60

# AI ç”Ÿæˆåˆ†å·å»ºè­°
volume_plan = ai_suggest_volumes(title, genre, theme, total_chapters)

# è¼¸å‡ºç¯„ä¾‹
{
  "volumes": [
    {
      "volume_number": 1,
      "title": "è’åŸè¦ºé†’",
      "main_plot": "ä¸»è§’åœ¨é‚Šç·£æ˜Ÿçƒç™¼ç¾å¤è€ç§‘æŠ€ï¼Œæ²å…¥æ˜Ÿéš›é™°è¬€",
      "key_locations": ["è’åŸæ˜Ÿ", "å»¢æ£„ç ”ç©¶ç«™", "é‚Šå¢ƒç©ºé–“ç«™"],
      "estimated_chapters": 12,
      "dramatic_goal": "ä¸»è§’ç²å¾—é—œéµç·šç´¢ï¼Œæ±ºå®šé›¢é–‹æ¯æ˜Ÿ"
    },
    {
      "volume_number": 2,
      "title": "è¯é‚¦è¿·å±€",
      "main_plot": "é€²å…¥äººé¡è¯é‚¦æ ¸å¿ƒå€ï¼Œç™¼ç¾æ”¿æ²»è…æ•—å’Œå¤–æ˜Ÿå¨è„…",
      "key_locations": ["é¦–éƒ½æ˜Ÿ", "è­°æœƒå¤§å»ˆ", "ç§˜å¯†å¯¦é©—å®¤"],
      "estimated_chapters": 18,
      "dramatic_goal": "æ­éœ²éƒ¨åˆ†çœŸç›¸ï¼Œé­åˆ°è¿½æ®º"
    },
    ...
  ]
}
```

#### æ–¹å¼äºŒï¼šæ‰‹å‹•äº’å‹•è¦åŠƒ

```bash
=== å°èªªåˆ†å·è¦åŠƒ ===

ç¬¬1å·è¨­å®š:
  å·å: è’åŸè¦ºé†’
  ä¸»ç·šåŠ‡æƒ…: ä¸»è§’ç™¼ç¾å¤è€ç§‘æŠ€
  ä¸»è¦å ´æ™¯: è’åŸæ˜Ÿ, ç ”ç©¶ç«™
  é è¨ˆç« ç¯€æ•¸: 12
  æœ¬å·ç›®æ¨™: ç²å¾—ç·šç´¢ä¸¦é›¢é–‹

ç¹¼çºŒæ·»åŠ ä¸‹ä¸€å·? [Y/n]: Y

ç¬¬2å·è¨­å®š:
  ...
```

### 4.4 å·å®Œæˆåˆ¤æ–·æ©Ÿåˆ¶

#### å¤šé‡æª¢æŸ¥ç­–ç•¥

```python
def should_end_volume(chapter_num, volume_info):
    """åˆ¤æ–·æ˜¯å¦è©²çµæŸç•¶å‰å·"""
    
    checks = []
    
    # æª¢æŸ¥1ï¼šç« ç¯€æ•¸ç¯„åœ
    chapters_in_vol = volume_info['actual_chapters']
    estimated = volume_info['estimated_chapters']
    
    if chapters_in_vol < estimated - 2:
        return False, "ç« ç¯€æ•¸æœªé”æ¨™"
    
    # æª¢æŸ¥2ï¼šAI åˆ¤æ–·ç›®æ¨™é”æˆ
    if chapters_in_vol >= estimated - 2:
        goal = volume_info['dramatic_goal']
        recent_text = get_recent_chapters(3)
        
        ai_check = ai_check_goal_achieved(goal, recent_text)
        checks.append(ai_check)
    
    # æª¢æŸ¥3ï¼šé—œéµè©æª¢æ¸¬
    keyword_check = keyword_based_check(goal, recent_text)
    checks.append(keyword_check)
    
    # æª¢æŸ¥4ï¼šç¡¬æ€§ä¸Šé™
    if chapters_in_vol >= estimated + 3:
        return True, "ç« ç¯€æ•¸è¶…é™ï¼Œå¼·åˆ¶çµæŸ"
    
    # è‡³å°‘2å€‹æª¢æŸ¥é€šé
    if sum(checks) >= 2:
        return True, "æˆ²åŠ‡ç›®æ¨™é”æˆ"
    
    return False, "ç¹¼çºŒç•¶å‰å·"
```

#### ç¡¬æ€§é™åˆ¶

```python
class VolumeConfig:
    MIN_CHAPTERS = 8   # æœ€å°‘8ç« 
    MAX_CHAPTERS = 20  # æœ€å¤š20ç« 
```

é€™æ¨£å¯ä»¥é˜²æ­¢ï¼š
- å·å¤ªçŸ­ï¼ˆåŠ‡æƒ…ä¸å®Œæ•´ï¼‰
- å·å¤ªé•·ï¼ˆå¤±æ§ï¼‰

### 4.5 å·æ‘˜è¦ç”Ÿæˆ

**ç‚ºä½•éœ€è¦å·æ‘˜è¦ï¼Ÿ**

ç•¶å°èªªæœ‰ 100 ç« æ™‚ï¼Œä¸å¯èƒ½æŠŠæ‰€æœ‰ç« ç¯€éƒ½æ”¾é€²ä¸Šä¸‹æ–‡ã€‚å·æ‘˜è¦å¯ä»¥ï¼š
- å£“ç¸® 90% ä»¥ä¸Šçš„å…§å®¹
- ä¿ç•™é—œéµä¿¡æ¯
- è®“å¾ŒçºŒç« ç¯€èƒ½ã€Œè¨˜ä½ã€å‰é¢çš„é‡é»

**å·æ‘˜è¦åŒ…å«ä»€éº¼ï¼Ÿ**

```
ã€ç¬¬ä¸€å·æ‘˜è¦ç¯„ä¾‹ã€‘

å·åï¼šè’åŸè¦ºé†’
ç« ç¯€ï¼šç¬¬1-12ç« 

== æœ¬å·ä¸»ç·š ==
ä¸»è§’ææ˜åœ¨è’åŸæ˜Ÿç™¼ç¾å¤è€çš„å¤–æ˜Ÿç§‘æŠ€éºè·¡ï¼Œæ„å¤–å•Ÿå‹•äº†æ²‰ç¡åƒå¹´çš„
AIç³»çµ±ã€Œé˜¿çˆ¾æ³•ã€ï¼Œå¾ä¸­å¾—çŸ¥äººé¡æ–‡æ˜é¢è‡¨çš„çœŸæ­£å¨è„…...

== é—œéµè½‰æŠ˜é» ==
1. ç¬¬3ç« ï¼šç™¼ç¾éºè·¡å…¥å£
2. ç¬¬7ç« ï¼šå•Ÿå‹•é˜¿çˆ¾æ³•ï¼Œå¾—çŸ¥çœŸç›¸
3. ç¬¬10ç« ï¼šé­é‡è¯é‚¦ç‰¹å·¥è¿½æ®º
4. ç¬¬12ç« ï¼šæ±ºå®šé›¢é–‹è’åŸæ˜Ÿ

== è§’è‰²ç™¼å±• ==
- ææ˜ï¼šå¾æ‡µæ‡‚å°‘å¹´åˆ°èªè­˜åˆ°è‡ªå·±çš„ä½¿å‘½
- é˜¿çˆ¾æ³•ï¼šå¾æ²‰ç¡çš„AIåˆ°æˆç‚ºé‡è¦å¤¥ä¼´
- å¼µéšŠé•·ï¼šå‡ºå ´æ™‚çš„å°å¸«ï¼Œåœ¨ç¬¬11ç« çŠ§ç‰²

== æ–°å¢è¬åœ˜ ==
- å¤–æ˜Ÿæ–‡æ˜ç‚ºä½•æ»…äº¡ï¼Ÿ
- äººé¡çœŸæ­£çš„èµ·æºæ˜¯ä»€éº¼ï¼Ÿ
- è¯é‚¦é«˜å±¤éš±çäº†ä»€éº¼ï¼Ÿ

== å·²è§£è¬åœ˜ ==
- è’åŸæ˜Ÿçš„ç•°å¸¸è¼»å°„ä¾†æºï¼ˆå¤ä»£èƒ½æºæ ¸å¿ƒï¼‰

== æ‰¿ä¸Šå•Ÿä¸‹ ==
æœ¬å·ç‚ºå…¨æ›¸å¥ å®šåŸºèª¿ï¼Œä¸»è§’å¸¶è‘—é˜¿çˆ¾æ³•å’ŒçœŸç›¸ç¢ç‰‡ï¼Œ
è¸ä¸Šå‰å¾€è¯é‚¦ä¸­å¿ƒçš„æ—…ç¨‹ã€‚ç¬¬äºŒå·å°‡æ­éœ²æ›´æ·±å±¤çš„é™°è¬€ã€‚
```

**ç”Ÿæˆæç¤ºè©**:

```python
def generate_volume_summary(volume_chapters):
    prompt = f"""
è«‹ç‚ºé€™ä¸€å·å°èªªç”Ÿæˆç²¾ç…‰æ‘˜è¦ (500-800å­—)ï¼Œå¿…é ˆåŒ…å«:

1. ã€æœ¬å·ä¸»ç·šã€‘æ ¸å¿ƒåŠ‡æƒ…ç™¼å±•
2. ã€é—œéµè½‰æŠ˜ã€‘3-5å€‹é‡è¦è½‰æŠ˜é»ï¼ˆæ¨™è¨»ç« ç¯€ï¼‰
3. ã€è§’è‰²è®ŠåŒ–ã€‘ä¸»è¦è§’è‰²çš„æˆé•·
4. ã€æ–°å¢è¬åœ˜ã€‘æœ¬å·å¼•å…¥çš„æœªè§£ä¹‹è¬
5. ã€å·²è§£è¬åœ˜ã€‘æœ¬å·è§£é–‹çš„ä¼ç­†
6. ã€æ‰¿ä¸Šå•Ÿä¸‹ã€‘èˆ‡å‰å·è¯ç¹«ã€å°ä¸‹å·é‹ªå¢Š

æœ¬å·æ‰€æœ‰ç« ç¯€:
{volume_chapters}

å·æ‘˜è¦:
"""
    return api_call(prompt)
```

---

## 5. ä¸Šä¸‹æ–‡ç®¡ç†æ–¹æ¡ˆ

### 5.1 æ ¸å¿ƒæŒ‘æˆ°

```
å•é¡Œï¼šå¦‚ä½•è®“ç¬¬ 100 ç« è¨˜ä½ç¬¬ 1 ç« çš„å…§å®¹ï¼Ÿ

çŸ›ç›¾ï¼š
  éœ€è¦ï¼šè®€å–æ‰€æœ‰å‰æ–‡ (ä¿è­‰ä¸€è‡´æ€§)
    VS
  é™åˆ¶ï¼šContext Window æœ‰ä¸Šé™

èˆ‰ä¾‹ï¼š
  ç¬¬ 100 ç« ç”Ÿæˆæ™‚
  - å¦‚æœåªçœ‹ç¬¬ 99 ç«  â†’ å¯èƒ½èˆ‡ç¬¬ 5 ç« çŸ›ç›¾
  - å¦‚æœçœ‹å…¨éƒ¨ 99 ç«  â†’ è¶…é 150,000 tokens âŒ
```

### 5.2 è§£æ±ºæ–¹æ¡ˆï¼šé›™å±¤æ¶æ§‹

```
è·¨å·å±¤ç´šï¼ˆé•·è·é›¢å£“ç¸®ï¼‰
â”œâ”€ ç¬¬1å·æ‘˜è¦ (800å­—)
â”œâ”€ ç¬¬2å·æ‘˜è¦ (800å­—)
â”œâ”€ ç¬¬3å·æ‘˜è¦ (800å­—)
â”œâ”€ ...
â””â”€ ã€ç¬¬Nå·ã€‘â† ç•¶å‰å·

å·å…§å±¤ç´šï¼ˆé«˜è§£æåº¦ï¼‰
â”œâ”€ RAG èªç¾©æª¢ç´¢ â†’ æ‰¾åˆ°æœ¬å·æœ€ç›¸é—œçš„ç‰‡æ®µ
â”œâ”€ é‡‘å­—å¡”åˆ†å±¤ â†’ çµæ§‹åŒ–çš„æ‘˜è¦
â””â”€ ä¸Šä¸€ç« å®Œæ•´ â†’ ç·Šå¯†æ‰¿æ¥
```

### 5.3 è·¨å·å£“ç¸®ç­–ç•¥

**è·é›¢è¶Šé ï¼Œå£“ç¸®è¶Šå¤š**

```python
def get_historical_volumes_context(current_volume):
    """ç²å–æ­·å²å·çš„ä¸Šä¸‹æ–‡"""
    
    summaries = []
    
    for vol_num in range(1, current_volume):
        distance = current_volume - vol_num
        
        if distance > 5:
            # è¶…é5å·ï¼šæ¥µç°¡ç‰ˆ (200å­—)
            summary = volume_summaries[vol_num][:200] + "..."
        elif distance > 2:
            # 2-5å·ï¼šä¸­ç­‰è©³ç´° (500å­—)
            summary = volume_summaries[vol_num][:500]
        else:
            # æœ€è¿‘2å·ï¼šå®Œæ•´ç‰ˆ (800å­—)
            summary = volume_summaries[vol_num]
        
        summaries.append(f"ç¬¬{vol_num}å·ï¼š{summary}")
    
    return "\n\n".join(summaries)
```

**Token ä½¿ç”¨ç¯„ä¾‹ï¼ˆç¬¬ 17 å·ç¬¬ 8 ç« ï¼‰**

```
æ­·å²å·æ‘˜è¦ï¼š
â”œâ”€ ç¬¬1-11å·æ¥µç°¡ (æ¯å·200å­—) = 2,200å­— â†’ 3,300 tokens
â”œâ”€ ç¬¬12-15å·ä¸­ç­‰ (æ¯å·500å­—) = 2,000å­— â†’ 3,000 tokens
â””â”€ ç¬¬16å·å®Œæ•´ (800å­—) â†’ 1,200 tokens

å°è¨ˆï¼š7,500 tokens
```

### 5.4 å·å…§ RAG + é‡‘å­—å¡”

#### RAG (Retrieval-Augmented Generation)

**åŸç†**ï¼šæŠŠç« ç¯€è½‰æˆå‘é‡ï¼ŒæŒ‰ç›¸ä¼¼åº¦æª¢ç´¢

```python
# 1. å­˜å„²éšæ®µï¼šæ¯å¯«å®Œä¸€ç« 
chapter_text = "ææ˜ç«™åœ¨æ‡¸å´–é‚Š..."
embedding = encoder.encode(chapter_text)  # è½‰æˆ768ç¶­å‘é‡
vector_db.store(chapter_num, embedding, chapter_text)

# 2. ç”Ÿæˆéšæ®µï¼šå¯«ç¬¬50ç« æ™‚
query = "ç¬¬50ç« é‡é»ï¼šææ˜å›åˆ°æ‡¸å´–åšå‡ºæ±ºå®š"
query_embedding = encoder.encode(query)

# æœå°‹æœ€ç›¸é—œçš„10å€‹ç‰‡æ®µ
relevant_chunks = vector_db.search(query_embedding, top_k=10)

# çµæœå¯èƒ½åŒ…æ‹¬ï¼š
# - ç¬¬3ç« ï¼šææ˜ç¬¬ä¸€æ¬¡ä¾†åˆ°æ‡¸å´–
# - ç¬¬27ç« ï¼šææ˜åœ¨æ‡¸å´–é‡è¦‹å¸«çˆ¶
# - ç¬¬45ç« ï¼šæ‡¸å´–ä¸Šçš„ç´„å®š
```

**å„ªå‹¢**ï¼š
- âœ… è‡ªå‹•æ‰¾åˆ°ç›¸é—œå…§å®¹ï¼ˆå³ä½¿æ˜¯å¾ˆä¹…ä¹‹å‰çš„ç« ç¯€ï¼‰
- âœ… Token ä½¿ç”¨å°‘ï¼ˆåªè¼‰å…¥ç›¸é—œç‰‡æ®µï¼‰
- âœ… èªç¾©ç†è§£ï¼ˆä¸åªæ˜¯é—œéµå­—åŒ¹é…ï¼‰

#### é‡‘å­—å¡”åˆ†å±¤

```
Level 3: å…¨å·ä¸»ç·š (200å­—)
    â†“
Level 2: ç« ç¯€æ‘˜è¦ (æ¯ç« 200å­—)
    â†“
Level 1: æ®µè½æ‘˜è¦ (æ¯æ®µ50å­—)
    â†“
Level 0: å®Œæ•´ç« ç¯€ (æ¯ç« 3000å­—)
```

**ç”Ÿæˆç¬¬ 10 ç« æ™‚çš„ä¸Šä¸‹æ–‡æ§‹å»º**ï¼š

```python
def build_pyramid_context(target_chapter):
    """æ§‹å»ºé‡‘å­—å¡”å¼ä¸Šä¸‹æ–‡"""
    
    context = []
    
    # Level 3: å…¨å·ä¸»ç·š
    context.append(f"ã€æœ¬å·ä¸»ç·šã€‘\n{volume_main_plot}")
    
    # Level 2: å‰é¢ç« ç¯€çš„æ‘˜è¦
    for ch in range(1, target_chapter):
        summary = chapter_summaries[ch]  # 200å­—
        context.append(f"ç¬¬{ch}ç« ï¼š{summary}")
    
    # Level 0: ä¸Šä¸€ç« å®Œæ•´
    prev_chapter = load_chapter(target_chapter - 1)
    context.append(f"ã€ä¸Šä¸€ç« å®Œæ•´ã€‘\n{prev_chapter}")
    
    return "\n\n".join(context)
```

### 5.5 å®Œæ•´çš„ä¸Šä¸‹æ–‡æ§‹å»ºæµç¨‹

```python
def build_complete_context(chapter_num, volume_num, chapter_hint):
    """ç‚ºç« ç¯€æ§‹å»ºå®Œæ•´ä¸Šä¸‹æ–‡"""
    
    parts = []
    
    # === ç¬¬ä¸€å±¤ï¼šå…¨å±€å¤§ç¶± ===
    parts.append(global_outline)  # 1,000 tokens
    
    # === ç¬¬äºŒå±¤ï¼šæ­·å²å·æ‘˜è¦ ===
    if volume_num > 1:
        historical = get_historical_volumes_context(volume_num)
        parts.append(historical)  # ~7,500 tokens
    
    # === ç¬¬ä¸‰å±¤ï¼šæœ¬å· RAG æª¢ç´¢ ===
    relevant_chunks = rag_retrieve(chapter_hint, top_k=10)
    parts.append(format_rag_results(relevant_chunks))  # ~2,000 tokens
    
    # === ç¬¬å››å±¤ï¼šæœ¬å·é‡‘å­—å¡”æ‘˜è¦ ===
    pyramid = build_pyramid_context(chapter_num)
    parts.append(pyramid)  # ~2,000 tokens
    
    # === ç¬¬äº”å±¤ï¼šä¸Šä¸€ç« å®Œæ•´ ===
    if chapter_num > 1:
        prev = load_chapter(chapter_num - 1)
        parts.append(f"ã€ä¸Šä¸€ç« å®Œæ•´ã€‘\n{prev}")  # ~4,500 tokens
    
    # ç¸½è¨ˆï¼š~17,000 tokens
    # å¦‚æœæ¨¡å‹ context window æ˜¯ 32Kï¼Œå®Œå…¨å¤ ç”¨ï¼
    
    return "\n\n".join(parts)
```

### 5.6 Token é ç®—ç®¡ç†

**å•é¡Œ**ï¼šå¦‚æœç¸½ tokens è¶…éæ¨¡å‹é™åˆ¶æ€éº¼è¾¦ï¼Ÿ

**è§£æ±ºæ–¹æ¡ˆ**ï¼šå‹•æ…‹è£å‰ª

```python
def build_context_within_budget(chapter_num, max_tokens=20000):
    """ç¢ºä¿ä¸Šä¸‹æ–‡åœ¨ token é ç®—å…§"""
    
    parts = {
        'global': (global_outline, 1000, True),      # (å…§å®¹, tokens, å¿…é ˆ)
        'historical': (historical_vols, 7500, True),
        'rag': (rag_chunks, 2000, False),            # å¯é¸
        'pyramid': (pyramid_summary, 2000, False),
        'previous': (prev_chapter, 4500, True)
    }
    
    # å…ˆåŠ å…¥å¿…é ˆçš„
    selected = []
    used_tokens = 0
    
    for key, (content, tokens, required) in parts.items():
        if required:
            selected.append(content)
            used_tokens += tokens
    
    # å‰©é¤˜ç©ºé–“åˆ†é…çµ¦å¯é¸é …
    remaining = max_tokens - used_tokens
    
    for key, (content, tokens, required) in parts.items():
        if not required and tokens <= remaining:
            selected.append(content)
            remaining -= tokens
    
    return "\n\n".join(selected)
```

---

## 6. JSON è§£æå®¹éŒ¯

### 6.1 å•é¡Œåˆ†æ

AI ç”Ÿæˆçš„ JSON å¸¸è¦‹å•é¡Œï¼š

```python
# æœŸæœ›
{"volume_number": 1, "title": "è’åŸè¦ºé†’"}

# å¯¦éš›å¯èƒ½æ”¶åˆ°
"""
å¥½çš„ï¼Œé€™æ˜¯åˆ†å·è¦åŠƒï¼š

```json
{
  "å·è™Ÿ": 1,
  "æ¨™é¡Œ": "è’åŸè¦ºé†’"
}
```

å¸Œæœ›å°æ‚¨æœ‰å¹«åŠ©ï¼
"""
```

å•é¡Œï¼š
1. âŒ åŒ…è£¹åœ¨ markdown ä»£ç¢¼å¡Šä¸­
2. âŒ ä½¿ç”¨ä¸­æ–‡ key
3. âŒ æ·»åŠ äº†é–‹å ´ç™½å’Œçµå°¾
4. âŒ å¯èƒ½æœ‰é¡å¤–çš„è¨»é‡‹

### 6.2 æš´åŠ›æ¸…æ´—ç­–ç•¥

```python
import json
import re

class RobustJSONParser:
    """è¶…å¼·å®¹éŒ¯çš„ JSON è§£æå™¨"""
    
    def parse(self, response_text):
        """å˜—è©¦æ‰€æœ‰å¯èƒ½çš„è§£ææ–¹å¼"""
        
        # ç­–ç•¥1ï¼šç›´æ¥ parse
        try:
            return json.loads(response_text)
        except:
            pass
        
        # ç­–ç•¥2ï¼šæå– ```json``` åŒ…è£¹çš„å…§å®¹
        match = re.search(r'```json\s*\n(.*?)\n```', 
                         response_text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except:
                pass
        
        # ç­–ç•¥3ï¼šæå–ä»»ä½• ``` åŒ…è£¹çš„å…§å®¹
        match = re.search(r'```\s*\n(.*?)\n```', 
                         response_text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except:
                pass
        
        # ç­–ç•¥4ï¼šæ‰¾ç¬¬ä¸€å€‹ { å’Œæœ€å¾Œä¸€å€‹ }
        try:
            first = response_text.index('{')
            last = response_text.rindex('}')
            json_str = response_text[first:last+1]
            return json.loads(json_str)
        except:
            pass
        
        # ç­–ç•¥5ï¼šæ‰¾ç¬¬ä¸€å€‹ [ å’Œæœ€å¾Œä¸€å€‹ ]
        try:
            first = response_text.index('[')
            last = response_text.rindex(']')
            json_str = response_text[first:last+1]
            return json.loads(json_str)
        except:
            pass
        
        # å…¨éƒ¨å¤±æ•—
        raise ValueError(f"ç„¡æ³•è§£æ JSON:\n{response_text[:200]}...")
```

### 6.3 Key æ˜ å°„ä¿®æ­£

```python
def parse_with_key_mapping(self, response_text, key_map):
    """è§£æä¸¦ä¿®æ­£ key åç¨±"""
    
    # å…ˆè§£æ
    data = self.parse(response_text)
    
    # éæ­¸ä¿®æ­£ key
    return self._fix_keys(data, key_map)

def _fix_keys(self, data, key_map):
    """ä¿®æ­£ key åç¨±ï¼ˆæ”¯æ´ä¸­è‹±æ–‡æ··ç”¨ï¼‰"""
    
    if isinstance(data, dict):
        fixed = {}
        for k, v in data.items():
            # æ‰¾æ¨™æº– key
            standard_key = key_map.get(k, k)
            fixed[standard_key] = self._fix_keys(v, key_map)
        return fixed
    
    elif isinstance(data, list):
        return [self._fix_keys(item, key_map) for item in data]
    
    else:
        return data

# Key æ˜ å°„è¡¨ç¯„ä¾‹
key_map = {
    # ä¸­æ–‡ â†’ è‹±æ–‡
    "å·è™Ÿ": "volume_number",
    "æ¨™é¡Œ": "title",
    "å·å": "title",
    
    # å…¶ä»–å¯èƒ½çš„è®Šé«”
    "vol_num": "volume_number",
    "volume": "volume_number",
    "name": "title",
}

# ä½¿ç”¨
parser = RobustJSONParser()
result = parser.parse_with_key_mapping(ai_response, key_map)
```

### 6.4 é‡è©¦æ©Ÿåˆ¶

```python
def generate_json_with_retry(self, prompt, max_attempts=3):
    """å¸¶é‡è©¦çš„ JSON ç”Ÿæˆ"""
    
    for attempt in range(max_attempts):
        try:
            # ç”Ÿæˆ
            response = api_call(prompt)
            
            # è§£æ
            data = parser.parse_with_key_mapping(response, key_map)
            
            # é©—è­‰
            if validate_structure(data):
                return data
            else:
                print(f"ç¬¬{attempt+1}æ¬¡ï¼šæ ¼å¼ä¸ç¬¦ï¼Œé‡è©¦...")
                # åœ¨ prompt ä¸­åŠ å…¥éŒ¯èª¤æç¤º
                prompt = add_error_feedback(prompt, data)
        
        except Exception as e:
            print(f"ç¬¬{attempt+1}æ¬¡å¤±æ•—ï¼š{e}")
            if attempt == max_attempts - 1:
                raise
    
    raise ValueError("å¤šæ¬¡å˜—è©¦å¾Œä»ç„¡æ³•ç”Ÿæˆæœ‰æ•ˆ JSON")
```

### 6.5 æ‰‹å‹•é™ç´šæ–¹æ¡ˆ

```python
def fallback_interactive_input():
    """é™ç´šæ–¹æ¡ˆï¼šæ‰‹å‹•è¼¸å…¥"""
    
    print("\nè‡ªå‹•ç”Ÿæˆå¤±æ•—ï¼Œæ”¹ç”¨æ‰‹å‹•è¼¸å…¥")
    
    volumes = []
    while True:
        print(f"\nç¬¬{len(volumes)+1}å·:")
        title = input("  å·å: ")
        if not title:
            break
        
        plot = input("  ä¸»ç·š: ")
        locations = input("  å ´æ™¯(é€—è™Ÿåˆ†éš”): ").split(',')
        chapters = int(input("  ç« ç¯€æ•¸: ") or "10")
        goal = input("  ç›®æ¨™: ")
        
        volumes.append({
            'volume_number': len(volumes) + 1,
            'title': title,
            'main_plot': plot,
            'key_locations': [l.strip() for l in locations],
            'estimated_chapters': chapters,
            'dramatic_goal': goal
        })
        
        if input("\nç¹¼çºŒ? [Y/n]: ").lower() == 'n':
            break
    
    return {'volumes': volumes}
```

---

## 7. æç¤ºè©ç®¡ç†

### 7.1 æ ¸å¿ƒå•é¡Œ

**AI æœƒéºå¿˜å’Œç”¢ç”Ÿå¹»è¦º**

```
ç¬¬1æ¬¡ç”Ÿæˆ: AI å¾ˆä¹–ï¼Œå®Œå…¨æŒ‰ç…§æŒ‡ç¤º
    â†“
ç¬¬5æ¬¡ç”Ÿæˆ: AI é–‹å§‹ã€Œç†è§£ã€ä½ çš„æ„æ€ï¼Œè‡ªä½œä¸»å¼µ
    â†“  
ç¬¬10æ¬¡ç”Ÿæˆ: AI å®Œå…¨å¿˜è¨˜æœ€åˆçš„è¦å‰‡ï¼Œé–‹å§‹ freestyle
    â†“
ç¬¬20æ¬¡ç”Ÿæˆ: AI ç”¢ç”Ÿå¹»è¦ºï¼Œæ··æ·†ä¸åŒç« ç¯€çš„å…§å®¹
```

### 7.2 è§£æ±ºæ–¹æ¡ˆï¼šæ¯æ¬¡é‡å»ºæç¤ºè©

**é—œéµåŸå‰‡**ï¼š
- âœ… æ¯æ¬¡éƒ½æ˜¯å…¨æ–°çš„å°è©±
- âœ… ä¸ç´¯ç©æ­·å² messages
- âœ… æ¯æ¬¡éƒ½æ³¨å…¥å®Œæ•´è¦å‰‡

```python
# âŒ éŒ¯èª¤åšæ³•
messages_history = []  # ç´¯ç©æ‰€æœ‰å°è©±

def generate_chapter(n):
    messages_history.append({
        "role": "user",
        "content": f"å¯«ç¬¬{n}ç« "
    })
    response = api_call(messages_history)  # æœƒè¢«æ­·å²å½±éŸ¿
    messages_history.append({"role": "assistant", "content": response})

# âœ… æ­£ç¢ºåšæ³•
def generate_chapter(n):
    # æ¯æ¬¡é‡æ–°æ§‹å»ºå®Œæ•´æç¤ºè©
    full_prompt = build_complete_prompt(n)
    
    # åªç”¨é€™ä¸€æ¬¡çš„ message
    messages = [{"role": "user", "content": full_prompt}]
    
    # å®Œå…¨ç¨ç«‹çš„èª¿ç”¨
    response = api_call(messages)
    return response
```

### 7.3 æç¤ºè©æ¨¡æ¿ç³»çµ±

```python
class PromptTemplateManager:
    def __init__(self):
        # æ ¸å¿ƒç³»çµ±è¦å‰‡ï¼ˆæ°¸é ä¸è®Šï¼‰
        self.SYSTEM_CORE = """
ä½ æ˜¯å°ˆæ¥­å°èªªä½œå®¶ã€‚

æ ¸å¿ƒè¦å‰‡ï¼ˆæ°¸é éµå®ˆï¼‰:
1. åš´æ ¼æŒ‰ç…§å¤§ç¶±å‰µä½œ
2. ä¿æŒè§’è‰²æ€§æ ¼ä¸€è‡´
3. å»¶çºŒå‰æ–‡åŠ‡æƒ…
4. å­—æ•¸ 2500-3500 å­—
5. ä¸æ·»åŠ ç« ç¯€æ¨™é¡Œ
6. ç¬¬ä¸‰äººç¨±æ•˜è¿°

ç¦æ­¢äº‹é …:
- ä¸è¦è·³å‡ºæ•…äº‹åšæ—ç™½
- ä¸è¦ç·¨é€ å¤§ç¶±ä¸­æ²’æœ‰çš„è¨­å®š
- ä¸è¦è®“è§’è‰²çªç„¶æ€§æ ¼å¤§è®Š
"""
        
        # æ ¼å¼æ§åˆ¶
        self.FORMAT_RULES = """
è¼¸å‡ºæ ¼å¼:
1. åªè¼¸å‡ºæ­£æ–‡
2. ä¸è¦ ``` æ¨™è¨˜
3. æ®µè½é–“ç©ºè¡Œåˆ†éš”
4. ç›´æ¥é–‹å§‹ï¼Œä¸è¦é–‹å ´ç™½
5. çµå°¾ä¸è¦ã€Œæœ¬ç« å®Œã€
"""
        
        # ä¸€è‡´æ€§è¦æ±‚
        self.CONSISTENCY_RULES = """
ä¸€è‡´æ€§è¦æ±‚:
1. ä»”ç´°é–±è®€ã€å‰æ–‡å›é¡§ã€‘
2. è§’è‰²è¨­å®šå¿…é ˆä¸€è‡´
3. æ™‚é–“ç·šåˆç†
4. ä¸é‡è¤‡å·²ç™¼ç”Ÿäº‹ä»¶
5. è¨­å®šå‰å¾Œçµ±ä¸€
"""
    
    def build_chapter_prompt(self, chapter_num, context_data):
        """æ§‹å»ºå®Œæ•´æç¤ºè©"""
        
        parts = []
        
        # 1. ç³»çµ±è¦å‰‡ï¼ˆæœ€é«˜å„ªå…ˆç´šï¼‰
        parts.append(self.SYSTEM_CORE)
        parts.append(self.FORMAT_RULES)
        parts.append(self.CONSISTENCY_RULES)
        
        # 2. ç•¶å‰ä»»å‹™
        parts.append(f"""
ç•¶å‰ä»»å‹™:
- ç¬¬ {chapter_num} ç« 
- æ‰€å±¬ï¼šç¬¬ {context_data['volume_num']} å·
""")
        
        # 3. å…¨å±€è¨­å®š
        parts.append(f"ã€å…¨æ›¸å¤§ç¶±ã€‘\n{context_data['global_outline']}")
        
        # 4. ç•¶å‰å·è¨­å®š
        parts.append(f"ã€æœ¬å·å¤§ç¶±ã€‘\n{context_data['volume_outline']}")
        
        # 5. è§’è‰²è¨­å®š
        parts.append(f"ã€è§’è‰²è¨­å®šã€‘\n{context_data['characters']}")
        
        # 6. å‰æ–‡å›é¡§
        parts.append(f"ã€å‰æ–‡å›é¡§ã€‘\n{context_data['history']}")
        
        # 7. ä¸Šä¸€ç« å®Œæ•´
        if context_data.get('previous_chapter'):
            parts.append(f"ã€ä¸Šä¸€ç« ã€‘\n{context_data['previous_chapter']}")
        
        # 8. æœ¬ç« è¦æ±‚
        parts.append(f"""
ç¾åœ¨å‰µä½œç¬¬ {chapter_num} ç« :
å­—æ•¸: 2500-3500å­—
é–‹å§‹:
""")
        
        return "\n\n".join(parts)
```

### 7.4 é€±æœŸæ€§å¼·åŒ–

```python
def generate_with_reinforcement(self, chapter_num, context):
    """å¸¶é€±æœŸæ€§å¼·åŒ–çš„ç”Ÿæˆ"""
    
    prompt = self.build_chapter_prompt(chapter_num, context)
    
    # æ¯ 5 ç« ï¼šåŠ å¼·ä¸€è‡´æ€§æª¢æŸ¥
    if chapter_num % 5 == 0:
        prompt = add_consistency_reminder(prompt)
    
    # æ¯ 10 ç« ï¼šå›é¡§å…¨å±€è¨­å®š
    if chapter_num % 10 == 0:
        prompt = add_global_review(prompt)
    
    return api_call(prompt)

def add_consistency_reminder(prompt):
    reminder = """
ğŸ” ä¸€è‡´æ€§æª¢æŸ¥é»:
è«‹ç¢ºèª:
â–¡ è§’è‰²æ€§æ ¼ä¸€è‡´
â–¡ æ™‚é–“ç·šåˆç†
â–¡ ç„¡é‡è¤‡æƒ…ç¯€
â–¡ ä¼ç­†æœªéºå¿˜
"""
    return reminder + "\n" + prompt
```

### 7.5 é˜²å¹»è¦ºæ©Ÿåˆ¶

```python
ANTI_HALLUCINATION_RULES = """
é˜²æ­¢éŒ¯èª¤:
1. åªä½¿ç”¨ã€è§’è‰²è¨­å®šã€‘ä¸­çš„è§’è‰²
2. ä¸ç·¨é€ å¤§ç¶±æ²’æœ‰çš„è¨­å®š
3. ä¸ç¢ºå®šçš„ç´°ç¯€å¯§å¯æ¨¡ç³Š
4. ä¸è®“å·²æ­»è§’è‰²å¾©æ´»
5. åœ°åç‰©å“èˆ‡å‰æ–‡ä¸€è‡´

æª¢æŸ¥æ¸…å–®:
- é€™å€‹è§’è‰²ä¹‹å‰å‡ºç¾éå—ï¼Ÿ
- é€™å€‹è¨­å®šå‰æ–‡æéå—ï¼Ÿ
- é€™æœƒçŸ›ç›¾å—ï¼Ÿ
"""

def build_safe_prompt(self, chapter_num, context):
    """æ§‹å»ºé˜²å¹»è¦ºæç¤ºè©"""
    
    prompt = f"""
{ANTI_HALLUCINATION_RULES}

ä½ åªèƒ½ä½¿ç”¨ä»¥ä¸‹è³‡æº:

ã€å·²ç¢ºå®šçš„è§’è‰²ã€‘
{list_confirmed_characters(context)}

ã€å·²ç¢ºå®šçš„åœ°é»ã€‘
{list_confirmed_locations(context)}

å¦‚éœ€æ–°å…ƒç´ ï¼Œä¿æŒæ¬¡è¦å’Œæ¨¡ç³Šã€‚

ç¾åœ¨å‰µä½œç¬¬ {chapter_num} ç« :
"""
    return prompt
```

---

## 8. ç”Ÿæˆç›£æ§çµ±è¨ˆ

### 8.1 ç›£æ§æŒ‡æ¨™

```python
class NovelGenerationMonitor:
    """ç”Ÿæˆç›£æ§ç³»çµ±"""
    
    def __init__(self, project_name):
        self.project_name = project_name
        self.start_time = time.time()
        
        # åŸºç¤çµ±è¨ˆ
        self.stats = {
            'total_chapters': 0,
            'total_volumes': 0,
            'total_words': 0,
            'total_tokens_input': 0,
            'total_tokens_output': 0,
            'total_cost_rmb': 0.0,
            'generation_times': [],
            'regeneration_count': 0,
            'quality_issues': [],
        }
        
        # è©³ç´°è¨˜éŒ„
        self.chapter_logs = []
        self.api_calls = []
        self.errors = []
```

### 8.2 ç« ç¯€ç´šç›£æ§

```python
def start_chapter(self, chapter_num, volume_num):
    """é–‹å§‹ç”Ÿæˆç« ç¯€"""
    return {
        'chapter_num': chapter_num,
        'volume_num': volume_num,
        'start_time': time.time(),
        'attempts': 0
    }

def end_chapter(self, session, chapter_text, tokens_in, tokens_out, cost):
    """çµæŸç« ç¯€ç”Ÿæˆ"""
    
    duration = time.time() - session['start_time']
    word_count = len(chapter_text)
    
    # æ›´æ–°çµ±è¨ˆ
    self.stats['total_chapters'] += 1
    self.stats['total_words'] += word_count
    self.stats['total_tokens_input'] += tokens_in
    self.stats['total_tokens_output'] += tokens_out
    self.stats['total_cost_rmb'] += cost
    self.stats['generation_times'].append(duration)
    
    # è¨˜éŒ„æ—¥èªŒ
    log_entry = {
        'chapter_num': session['chapter_num'],
        'volume_num': session['volume_num'],
        'word_count': word_count,
        'tokens_input': tokens_in,
        'tokens_output': tokens_out,
        'cost_rmb': cost,
        'duration_seconds': duration,
        'attempts': session['attempts'],
        'timestamp': datetime.now().isoformat()
    }
    
    self.chapter_logs.append(log_entry)
    return log_entry
```

### 8.3 å³æ™‚é€²åº¦é¡¯ç¤º

```python
def print_progress(self):
    """åˆ—å°é€²åº¦"""
    
    print("\n" + "="*60)
    print(f"ğŸ“Š ã€Š{self.project_name}ã€‹ç”Ÿæˆé€²åº¦")
    print("="*60)
    
    print(f"å·²ç”Ÿæˆç« ç¯€............ {self.stats['total_chapters']}")
    print(f"å·²å®Œæˆå·æ•¸............ {self.stats['total_volumes']}")
    print(f"ç¸½å­—æ•¸................ {self.stats['total_words']:,}")
    print(f"ç¸½æˆæœ¬................ Â¥{self.stats['total_cost_rmb']:.2f}")
    
    if self.stats['generation_times']:
        avg_time = sum(self.stats['generation_times']) / len(self.stats['generation_times'])
        print(f"å¹³å‡æ¯ç« è€—æ™‚.......... {avg_time:.1f}ç§’")
    
    print(f"é‡æ–°ç”Ÿæˆæ¬¡æ•¸.......... {self.stats['regeneration_count']}")
    print(f"å“è³ªå•é¡Œ.............. {len(self.stats['quality_issues'])}")
    
    print("="*60 + "\n")

# ä½¿ç”¨
monitor = NovelGenerationMonitor("æ˜Ÿéš›é‚Šç·£")

session = monitor.start_chapter(1, 1)
# ... ç”Ÿæˆç« ç¯€ ...
monitor.end_chapter(session, chapter_text, 5000, 3000, 0.003)

if chapter_num % 5 == 0:
    monitor.print_progress()
```

### 8.4 ç”Ÿæˆå ±å‘Š

```python
def generate_report(self, save_path=None):
    """ç”Ÿæˆè©³ç´°å ±å‘Š"""
    
    report = {
        'project_name': self.project_name,
        'generation_date': datetime.now().isoformat(),
        'summary': self.get_realtime_stats(),
        'chapter_logs': self.chapter_logs,
        'quality_issues': self.stats['quality_issues'],
        'errors': self.errors,
    }
    
    # åˆ†æ
    if self.chapter_logs:
        word_counts = [log['word_count'] for log in self.chapter_logs]
        times = [log['duration_seconds'] for log in self.chapter_logs]
        
        report['analysis'] = {
            'å¹³å‡ç« ç¯€å­—æ•¸': sum(word_counts) / len(word_counts),
            'æœ€çŸ­ç« ç¯€': min(word_counts),
            'æœ€é•·ç« ç¯€': max(word_counts),
            'å¹³å‡ç”Ÿæˆæ™‚é–“': sum(times) / len(times),
            'æœ€å¿«ç”Ÿæˆ': min(times),
            'æœ€æ…¢ç”Ÿæˆ': max(times),
        }
    
    # å„²å­˜
    if save_path:
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
    
    return report
```

### 8.5 è¦–è¦ºåŒ–çµ±è¨ˆ

```python
def plot_statistics(self):
    """ç¹ªè£½çµ±è¨ˆåœ–è¡¨"""
    
    import matplotlib.pyplot as plt
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    chapters = [log['chapter_num'] for log in self.chapter_logs]
    word_counts = [log['word_count'] for log in self.chapter_logs]
    times = [log['duration_seconds'] for log in self.chapter_logs]
    costs = [log['cost_rmb'] for log in self.chapter_logs]
    
    # 1. å­—æ•¸è¶¨å‹¢
    axes[0, 0].plot(chapters, word_counts, marker='o')
    axes[0, 0].axhline(y=3000, color='r', linestyle='--')
    axes[0, 0].set_title('ç« ç¯€å­—æ•¸è¶¨å‹¢')
    axes[0, 0].set_ylabel('å­—æ•¸')
    
    # 2. ç”Ÿæˆæ™‚é–“
    axes[0, 1].plot(chapters, times, marker='s', color='green')
    axes[0, 1].set_title('ç”Ÿæˆæ™‚é–“è¶¨å‹¢')
    axes[0, 1].set_ylabel('è€—æ™‚(ç§’)')
    
    # 3. Token ä½¿ç”¨
    tokens_in = [log['tokens_input'] for log in self.chapter_logs]
    axes[1, 0].plot(chapters, tokens_in, label='è¼¸å…¥tokens')
    axes[1, 0].set_title('Tokenä½¿ç”¨é‡')
    axes[1, 0].legend()
    
    # 4. ç´¯ç©æˆæœ¬
    cumulative = [sum(costs[:i+1]) for i in range(len(costs))]
    axes[1, 1].plot(chapters, cumulative, color='red')
    axes[1, 1].set_title('ç´¯ç©æˆæœ¬')
    axes[1, 1].set_ylabel('æˆæœ¬(Â¥)')
    
    plt.tight_layout()
    plt.savefig(f'{self.project_name}_statistics.png')
```

---

## 9. ç·©å­˜å„ªåŒ–ç³»çµ±

### 9.1 ç‚ºä½•éœ€è¦ç·©å­˜ï¼Ÿ

**å•é¡Œ**ï¼š
- å…¨å±€å¤§ç¶±æ¯ç« éƒ½è¦è¼‰å…¥ â†’ é‡è¤‡è®€å–æª”æ¡ˆ
- å·å¤§ç¶±æ¯ç« éƒ½è¦è¼‰å…¥ â†’ é‡è¤‡è®€å–
- è§’è‰²è¨­å®šæ¯ç« éƒ½è¦æŸ¥è©¢ â†’ é‡è¤‡æŸ¥è©¢
- ç« ç¯€æ‘˜è¦éœ€è¦ AI ç”Ÿæˆ â†’ é‡è¤‡è¨ˆç®—

**è§£æ±º**ï¼š
- è¨˜æ†¶é«”ç·©å­˜ï¼šå¸¸ç”¨æ•¸æ“š
- ç£ç¢Ÿç·©å­˜ï¼šç”Ÿæˆçš„æ‘˜è¦
- LRU ç·©å­˜ï¼šæœ€è¿‘ä½¿ç”¨çš„æ•¸æ“š

### 9.2 ç·©å­˜æ¶æ§‹

```python
class SmartCache:
    """æ™ºèƒ½ç·©å­˜ç³»çµ±"""
    
    def __init__(self, cache_dir=".cache"):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
        
        # è¨˜æ†¶é«”ç·©å­˜ï¼ˆå¿«ï¼‰
        self.memory_cache = {}
        
        # ç£ç¢Ÿç·©å­˜ï¼ˆæŒä¹…ï¼‰
        self.disk_cache_enabled = True
    
    def get(self, key):
        """ç²å–ç·©å­˜"""
        
        # å…ˆæŸ¥è¨˜æ†¶é«”
        if key in self.memory_cache:
            return self.memory_cache[key]
        
        # å†æŸ¥ç£ç¢Ÿ
        cache_file = f"{self.cache_dir}/{key}.pkl"
        if os.path.exists(cache_file):
            with open(cache_file, 'rb') as f:
                data = pickle.load(f)
                self.memory_cache[key] = data  # è¼‰å…¥åˆ°è¨˜æ†¶é«”
                return data
        
        return None
    
    def set(self, key, value, to_disk=True):
        """è¨­å®šç·©å­˜"""
        
        # å­˜è¨˜æ†¶é«”
        self.memory_cache[key] = value
        
        # å­˜ç£ç¢Ÿ
        if to_disk:
            cache_file = f"{self.cache_dir}/{key}.pkl"
            with open(cache_file, 'wb') as f:
                pickle.dump(value, f)
```

### 9.3 ç·©å­˜ç­–ç•¥

```python
class CachedNovelGenerator:
    """å¸¶ç·©å­˜çš„ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.cache = SmartCache()
    
    def get_global_outline(self, title, genre, theme, force=False):
        """ç²å–å…¨å±€å¤§ç¶±ï¼ˆå¸¶ç·©å­˜ï¼‰"""
        
        key = f"outline_{title}_{genre}_{theme}"
        
        if not force:
            cached = self.cache.get(key)
            if cached:
                print("âœ“ ä½¿ç”¨ç·©å­˜çš„å¤§ç¶±")
                return cached
        
        # ç”Ÿæˆæ–°çš„
        print("âš™ï¸ ç”Ÿæˆå¤§ç¶±...")
        outline = self._generate_outline(title, genre, theme)
        
        # ç·©å­˜
        self.cache.set(key, outline)
        
        return outline
    
    def get_chapter_summary(self, chapter_num, content):
        """ç²å–ç« ç¯€æ‘˜è¦ï¼ˆå¸¶ç·©å­˜ï¼‰"""
        
        # ç”¨å…§å®¹ hash ä½œç‚º key
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        key = f"summary_{chapter_num}_{content_hash}"
        
        cached = self.cache.get(key)
        if cached:
            return cached
        
        summary = self._generate_summary(content)
        self.cache.set(key, summary)
        
        return summary
```

### 9.4 LRU ç·©å­˜

```python
from functools import lru_cache

class CharacterManager:
    """è§’è‰²ç®¡ç†ï¼ˆä½¿ç”¨ LRU ç·©å­˜ï¼‰"""
    
    @lru_cache(maxsize=50)
    def get_character(self, name):
        """ç²å–è§’è‰²ï¼ˆè‡ªå‹•ç·©å­˜æœ€è¿‘ 50 å€‹ï¼‰"""
        return self._load_from_db(name)
```

### 9.5 é è¼‰å…¥

```python
def preload_common_data(self):
    """é è¼‰å…¥å¸¸ç”¨æ•¸æ“š"""
    
    print("âš™ï¸ é è¼‰å…¥ä¸­...")
    
    # é è¼‰å…¨å±€å¤§ç¶±
    self.cache.get('global_outline')
    
    # é è¼‰æ‰€æœ‰è§’è‰²è¨­å®š
    for char_name in all_characters:
        self.get_character(char_name)
    
    print("âœ“ é è¼‰å…¥å®Œæˆ")
```

---

## 10. ä¸€è‡´æ€§æª¢æŸ¥

### 10.1 æª¢æŸ¥ç¶­åº¦

```
ä¸€è‡´æ€§æª¢æŸ¥ç³»çµ±
â”œâ”€ è§’è‰²ä¸€è‡´æ€§
â”‚   â”œâ”€ æ€§æ ¼æ˜¯å¦ä¸€è‡´
â”‚   â”œâ”€ èƒ½åŠ›æ˜¯å¦åˆç†
â”‚   â”œâ”€ å¤–è²Œæ˜¯å¦çµ±ä¸€
â”‚   â””â”€ ç”Ÿæ­»ç‹€æ…‹
â”œâ”€ æ™‚é–“ç·šä¸€è‡´æ€§
â”‚   â”œâ”€ ç›¸å°æ™‚é–“åˆç†æ€§
â”‚   â”œâ”€ çµ•å°æ™‚é–“åˆç†æ€§
â”‚   â””â”€ äº‹ä»¶é †åº
â”œâ”€ è¨­å®šä¸€è‡´æ€§
â”‚   â”œâ”€ åœ°é»æè¿°
â”‚   â”œâ”€ ç‰©å“å±¬æ€§
â”‚   â””â”€ è¦å‰‡è¨­å®š
â””â”€ åŠ‡æƒ…é‚è¼¯
    â”œâ”€ äº‹ä»¶é‡è¤‡æª¢æ¸¬
    â”œâ”€ è¬åœ˜ç®¡ç†
    â””â”€ å› æœé—œä¿‚
```

### 10.2 è§’è‰²ä¸€è‡´æ€§è¿½è¹¤

```python
class CharacterConsistencyTracker:
    """è§’è‰²ä¸€è‡´æ€§è¿½è¹¤"""
    
    def __init__(self):
        self.character_db = {}  # è§’è‰²æ•¸æ“šåº«
        self.character_states = {}  # å„ç« ç‹€æ…‹
    
    def register_character(self, name, profile):
        """è¨»å†Šè§’è‰²"""
        self.character_db[name] = {
            'personality': profile['personality'],
            'appearance': profile['appearance'],
            'abilities': profile['abilities'],
            'relationships': profile['relationships']
        }
    
    def check(self, chapter_content, context):
        """æª¢æŸ¥ç« ç¯€ä¸­çš„è§’è‰²ä¸€è‡´æ€§"""
        
        issues = []
        
        # æå–å‡ºç¾çš„è§’è‰²
        chars = self._extract_characters(chapter_content)
        
        for char in chars:
            if char not in self.character_db:
                issues.append({
                    'type': 'unknown_character',
                    'severity': 'high',
                    'message': f'å‡ºç¾æœªå®šç¾©è§’è‰²ï¼š{char}'
                })
                continue
            
            # æª¢æŸ¥æ€§æ ¼
            if not self._check_personality(char, chapter_content):
                issues.append({
                    'type': 'personality_inconsistency',
                    'severity': 'medium',
                    'character': char,
                    'message': f'{char}çš„è¡Œç‚ºèˆ‡æ€§æ ¼è¨­å®šä¸ç¬¦'
                })
            
            # æª¢æŸ¥èƒ½åŠ›
            if not self._check_abilities(char, chapter_content):
                issues.append({
                    'type': 'ability_inconsistency',
                    'severity': 'high',
                    'character': char,
                    'message': f'{char}ä½¿ç”¨äº†æœªå®šç¾©çš„èƒ½åŠ›'
                })
            
            # æª¢æŸ¥ç”Ÿæ­»
            if self._is_dead(char, context):
                if not self._is_flashback(chapter_content):
                    issues.append({
                        'type': 'dead_character_appears',
                        'severity': 'critical',
                        'character': char,
                        'message': f'{char}å·²æ­»äº¡å»å†æ¬¡å‡ºç¾'
                    })
        
        return issues
```

### 10.3 æ™‚é–“ç·šè¿½è¹¤

```python
class TimelineTracker:
    """æ™‚é–“ç·šè¿½è¹¤"""
    
    def __init__(self):
        self.events = []  # äº‹ä»¶æ™‚é–“è»¸
        self.current_time = None
    
    def check(self, chapter_num, content):
        """æª¢æŸ¥æ™‚é–“ç·š"""
        
        issues = []
        
        # æå–æ™‚é–“æ¨™è¨˜
        markers = self._extract_time_markers(content)
        
        for marker in markers:
            if not self._is_chronologically_valid(marker):
                issues.append({
                    'type': 'timeline_error',
                    'severity': 'high',
                    'message': f'æ™‚é–“ç·šéŒ¯èª¤ï¼š{marker}'
                })
        
        return issues
    
    def _extract_time_markers(self, content):
        """æå–æ™‚é–“æ¨™è¨˜"""
        
        markers = []
        
        # ç›¸å°æ™‚é–“
        patterns = ['ç¬¬äºŒå¤©', 'ä¸‰å¤©å¾Œ', 'ä¸€é€±å¾Œ', 'åŒæ™‚']
        for p in patterns:
            if p in content:
                markers.append({'type': 'relative', 'marker': p})
        
        # çµ•å°æ™‚é–“
        import re
        dates = re.findall(r'\d+å¹´\d+æœˆ\d+æ—¥', content)
        for d in dates:
            markers.append({'type': 'absolute', 'marker': d})
        
        return markers
```

### 10.4 å®Œæ•´æª¢æŸ¥æµç¨‹

```python
class ConsistencyChecker:
    """ä¸€è‡´æ€§æª¢æŸ¥ç³»çµ±"""
    
    def __init__(self):
        self.character_tracker = CharacterConsistencyTracker()
        self.timeline_tracker = TimelineTracker()
        self.setting_tracker = SettingTracker()
        self.plot_tracker = PlotConsistencyTracker()
    
    def check_chapter(self, chapter_num, content, context):
        """å…¨é¢æª¢æŸ¥ç« ç¯€"""
        
        all_issues = []
        
        # 1. è§’è‰²
        issues = self.character_tracker.check(content, context)
        all_issues.extend(issues)
        
        # 2. æ™‚é–“ç·š
        issues = self.timeline_tracker.check(chapter_num, content)
        all_issues.extend(issues)
        
        # 3. è¨­å®š
        issues = self.setting_tracker.check(content, context)
        all_issues.extend(issues)
        
        # 4. åŠ‡æƒ…
        issues = self.plot_tracker.check(content, context)
        all_issues.extend(issues)
        
        # åˆ†ç´šè™•ç†
        critical = [i for i in all_issues if i['severity'] == 'critical']
        high = [i for i in all_issues if i['severity'] == 'high']
        
        if critical:
            print(f"âŒ ç™¼ç¾ {len(critical)} å€‹åš´é‡å•é¡Œ")
            for issue in critical:
                print(f"   - {issue['message']}")
            return False, all_issues
        
        if high:
            print(f"âš ï¸  ç™¼ç¾ {len(high)} å€‹é‡è¦å•é¡Œ")
            for issue in high:
                print(f"   - {issue['message']}")
        
        return True, all_issues

# ä½¿ç”¨
checker = ConsistencyChecker()
ok, issues = checker.check_chapter(chapter_num, content, context)

if not ok:
    print("éœ€è¦é‡æ–°ç”Ÿæˆ")
```

---

## 11. å®Œæ•´ç¨‹å¼ç¢¼

### 11.1 å°ˆæ¡ˆçµæ§‹

```
novel-generator/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generator.py          # æ ¸å¿ƒç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ context_manager.py    # ä¸Šä¸‹æ–‡ç®¡ç†
â”‚   â””â”€â”€ api_client.py         # API èª¿ç”¨
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ json_parser.py        # JSON è§£æ
â”‚   â”œâ”€â”€ cache.py              # ç·©å­˜ç³»çµ±
â”‚   â”œâ”€â”€ monitor.py            # ç›£æ§çµ±è¨ˆ
â”‚   â””â”€â”€ consistency.py        # ä¸€è‡´æ€§æª¢æŸ¥
â”‚
â”œâ”€â”€ novel_generator.py        # ä¸»ç¨‹å¼
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### 11.2 requirements.txt

```txt
requests>=2.31.0
sentence-transformers>=2.2.0
chromadb>=0.4.0
matplotlib>=3.7.0
```

### 11.3 æ ¸å¿ƒç”Ÿæˆå™¨ç¯„ä¾‹

```python
# novel_generator.py

import requests
import json
import os
from datetime import datetime

class NovelGenerator:
    """AI å°èªªç”Ÿæˆå™¨ä¸»é¡åˆ¥"""
    
    def __init__(self, api_key, model="Qwen/Qwen2.5-7B-Instruct"):
        self.api_key = api_key
        self.model = model
        self.base_url = "https://api.siliconflow.cn/v1/chat/completions"
        self.project_dir = None
        
    def create_project(self, title):
        """å»ºç«‹å°ˆæ¡ˆ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.project_dir = f"novel_{title}_{timestamp}"
        os.makedirs(self.project_dir, exist_ok=True)
        os.makedirs(f"{self.project_dir}/volumes", exist_ok=True)
        print(f"âœ“ å°ˆæ¡ˆå»ºç«‹: {self.project_dir}")
    
    def generate(self, prompt, temperature=0.8, max_tokens=5000):
        """èª¿ç”¨ API ç”Ÿæˆå…§å®¹"""
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        
        response = requests.post(self.base_url, headers=headers, json=data)
        result = response.json()
        
        return result['choices'][0]['message']['content']
    
    def generate_chapter(self, chapter_num, context):
        """ç”Ÿæˆç« ç¯€"""
        
        prompt = self._build_chapter_prompt(chapter_num, context)
        chapter = self.generate(prompt)
        
        # å„²å­˜
        filename = f"{self.project_dir}/chapter_{chapter_num:02d}.txt"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(chapter)
        
        print(f"âœ“ ç¬¬{chapter_num}ç« å®Œæˆ ({len(chapter)}å­—)")
        return chapter
    
    def _build_chapter_prompt(self, chapter_num, context):
        """æ§‹å»ºæç¤ºè©"""
        
        prompt = f"""
ä½ æ˜¯å°ˆæ¥­å°èªªä½œå®¶ã€‚

{context['global_outline']}

{context['volume_outline']}

{context['previous_chapter']}

ç¾åœ¨å‰µä½œç¬¬{chapter_num}ç« ï¼Œå­—æ•¸2500-3500å­—:
"""
        return prompt

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    generator = NovelGenerator(api_key="your_api_key")
    generator.create_project("æ¸¬è©¦å°èªª")
    
    context = {
        'global_outline': "é€™æ˜¯ä¸€éƒ¨ç§‘å¹»å°èªª...",
        'volume_outline': "ç¬¬ä¸€å·è¬›è¿°...",
        'previous_chapter': ""
    }
    
    chapter = generator.generate_chapter(1, context)
```

---

## 12. ä½¿ç”¨æŒ‡å—

### 12.1 å¿«é€Ÿé–‹å§‹

**æ­¥é©Ÿ 1ï¼šå®‰è£ä¾è³´**

```bash
pip install -r requirements.txt
```

**æ­¥é©Ÿ 2ï¼šè¨­å®š API Key**

```bash
export SILICONFLOW_API_KEY="your_api_key_here"
```

**æ­¥é©Ÿ 3ï¼šåŸ·è¡Œç”Ÿæˆ**

```bash
python novel_generator.py
```

### 12.2 äº’å‹•æµç¨‹

```
=== AI å°èªªè‡ªå‹•ç”Ÿæˆå™¨ ===

å°èªªæ¨™é¡Œ: æ˜Ÿéš›é‚Šç·£
é¡å‹: ç§‘å¹»
ä¸»é¡Œ: äººé¡æ–‡æ˜å­˜çºŒ
é è¨ˆç« ç¯€: 60

é¸æ“‡åˆ†å·æ–¹å¼:
1. AI è‡ªå‹•å»ºè­°
2. æ‰‹å‹•è¦åŠƒ
[1]: 1

ç”Ÿæˆåˆ†å·è¦åŠƒä¸­...

å»ºè­°çµæ§‹:
ç¬¬1å·: è’åŸè¦ºé†’ (12ç« )
ç¬¬2å·: è¯é‚¦è¿·å±€ (18ç« )
...

æ¥å—? [Y/n]: Y

ç”Ÿæˆå…¨å±€å¤§ç¶±ä¸­...
âœ“ å¤§ç¶±å®Œæˆ

é–‹å§‹ç”Ÿæˆç¬¬1ç« ...
âœ“ ç¬¬1ç« å®Œæˆ (2,847å­—)

ç¹¼çºŒ? [Y/n]: Y
```

### 12.3 é€²éšä½¿ç”¨

**å¾æ–·é»æ¢å¾©:**

```bash
python novel_generator.py --continue novel_xxx_20250103/
```

**é‡æ–°ç”Ÿæˆç‰¹å®šç« ç¯€:**

```bash
python novel_generator.py --regenerate 5 --project novel_xxx/
```

**æŸ¥çœ‹çµ±è¨ˆ:**

```bash
python novel_generator.py --stats novel_xxx/
```

---

## 13. å¸¸è¦‹å•é¡Œ

### Q1: ç”Ÿæˆçš„å…§å®¹é‡è¤‡æ€éº¼è¾¦ï¼Ÿ

**A**: èª¿é«˜ temperature åƒæ•¸

```python
chapter = generator.generate(prompt, temperature=0.9)  # æé«˜åˆ° 0.9
```

### Q2: AI å¿˜è¨˜å‰é¢çš„è¨­å®šï¼Ÿ

**A**: æª¢æŸ¥æç¤ºè©æ˜¯å¦å®Œæ•´é‡å»º

```python
# ç¢ºä¿æ¯æ¬¡éƒ½é‡æ–°æ§‹å»ºå®Œæ•´æç¤ºè©
prompt = build_complete_prompt(chapter_num)
```

### Q3: JSON è§£æå¤±æ•—ï¼Ÿ

**A**: ä½¿ç”¨å®¹éŒ¯è§£æå™¨

```python
parser = RobustJSONParser()
data = parser.parse_with_key_mapping(response, key_map)
```

### Q4: Token è¶…é™æ€éº¼è¾¦ï¼Ÿ

**A**: å‹•æ…‹è£å‰ªä¸Šä¸‹æ–‡

```python
context = build_context_within_budget(chapter_num, max_tokens=20000)
```

### Q5: æˆæœ¬å¤ªé«˜ï¼Ÿ

**A**: ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹æˆ–æ¸›å°‘ç”Ÿæˆé•·åº¦

```python
# ä½¿ç”¨ 7B æ¨¡å‹
generator = NovelGenerator(model="Qwen/Qwen2.5-7B-Instruct")

# æ¸›å°‘ max_tokens
chapter = generator.generate(prompt, max_tokens=3000)
```

---

## é™„éŒ„ Aï¼šAPI åƒ¹æ ¼åƒè€ƒ

| æ¨¡å‹ | åƒ¹æ ¼ï¼ˆæ¯ 1K tokensï¼‰ |
|-----|-------------------|
| Qwen2.5-7B-Instruct | Â¥0.0007 |
| Qwen2.5-14B-Instruct | Â¥0.0014 |
| Qwen2.5-32B-Instruct | Â¥0.0035 |
| Qwen2.5-72B-Instruct | Â¥0.0070 |

**æˆæœ¬ä¼°ç®—ï¼ˆ100 ç« å°èªªï¼‰:**
- ä½¿ç”¨ 7B: ç´„ Â¥0.30
- ä½¿ç”¨ 14B: ç´„ Â¥0.60
- ä½¿ç”¨ 32B: ç´„ Â¥1.50

---

## é™„éŒ„ Bï¼šToken è¨ˆç®—

```python
# ç²—ä¼°ï¼šä¸­æ–‡ 1 å­— â‰ˆ 1.5 tokens

# ç²¾ç¢ºè¨ˆç®—
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B-Instruct")

def count_tokens(text):
    return len(tokenizer.encode(text))

# ä½¿ç”¨
tokens = count_tokens("é€™æ˜¯ä¸€æ®µæ¸¬è©¦æ–‡æœ¬")
print(f"Token æ•¸: {tokens}")
```

---

## é™„éŒ„ Cï¼šæ¨è–¦é–±è®€

- [Qwen2.5 å®˜æ–¹æ–‡æª”](https://qwen.readthedocs.io/)
- [çŸ½åŸºæµå‹• API æ–‡æª”](https://siliconflow.cn/docs)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)

---

## è®Šæ›´æ—¥èªŒ

**v1.0 (2025-01-03)**
- åˆå§‹ç‰ˆæœ¬
- å®Œæ•´æ¶æ§‹è¨­è¨ˆ
- æ ¸å¿ƒåŠŸèƒ½å¯¦ä½œ

---

**æ–‡æª”çµæŸ**

*å¦‚æœ‰å•é¡Œæˆ–å»ºè­°ï¼Œè«‹è¯ç¹«é–‹ç™¼è€…*
