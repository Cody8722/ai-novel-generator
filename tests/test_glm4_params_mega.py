#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
GLM-4 è¶…å¤§è¦æ¨¡åƒæ•¸æ¸¬è©¦ç³»çµ±

ç‰¹æ€§ï¼š
- æ”¯æŒ 600+ çµ„åƒæ•¸æ¸¬è©¦
- åˆ†æ‰¹åŸ·è¡Œï¼ˆé¿å… API éè¼‰ï¼‰
- æ–·é»çºŒå‚³ï¼ˆæ”¯æŒä¸­æ–·æ¢å¾©ï¼‰
- å¯¦æ™‚é€²åº¦ä¿å­˜
- è©³ç´°åˆ†æå ±å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    # åŸ·è¡Œå–®å€‹æ‰¹æ¬¡
    python tests/test_glm4_params_mega.py --batch 0

    # åŸ·è¡Œæ‰€æœ‰æ‰¹æ¬¡
    python tests/test_glm4_params_mega.py --run-all

    # å¾æª¢æŸ¥é»æ¢å¾©
    python tests/test_glm4_params_mega.py --resume

    # å¿«é€Ÿæ¨¡å¼ï¼ˆåƒ…ç”Ÿæˆå¤§ç¶±ï¼‰
    python tests/test_glm4_params_mega.py --run-all --quick
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import json
import time
import random
import argparse
import logging
from datetime import datetime
from typing import Dict, List, Tuple
from tests.test_glm4_params import GLM4ParamsTester

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MegaParamsTester:
    """è¶…å¤§è¦æ¨¡åƒæ•¸æ¸¬è©¦å™¨"""

    def __init__(self, api_key: str, quick_mode: bool = False, batch_size: int = 50):
        """
        åˆå§‹åŒ–è¶…å¤§è¦æ¨¡æ¸¬è©¦å™¨

        Args:
            api_key: API é‡‘é‘°
            quick_mode: å¿«é€Ÿæ¨¡å¼ï¼ˆåƒ…ç”Ÿæˆå¤§ç¶±ï¼‰
            batch_size: æ¯æ‰¹æ¸¬è©¦æ•¸é‡
        """
        self.api_key = api_key
        self.quick_mode = quick_mode
        self.batch_size = batch_size
        # æ‰¹æ¬¡æ•¸é‡æœƒåœ¨ç”Ÿæˆåƒæ•¸ç¶²æ ¼å¾Œè‡ªå‹•è¨ˆç®—

        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        self.output_dir = Path(__file__).parent.parent / "test_results" / "mega_test"
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # æª¢æŸ¥é»æ–‡ä»¶
        self.checkpoint_file = self.output_dir / "checkpoint.json"

        # ç”Ÿæˆåƒæ•¸ç¶²æ ¼
        logger.info("ğŸ”§ ç”Ÿæˆåƒæ•¸ç¶²æ ¼...")
        self.param_grid = self.generate_param_grid()

        # è‡ªå‹•è¨ˆç®—æ‰¹æ¬¡æ•¸é‡
        import math
        self.total_batches = math.ceil(len(self.param_grid) / self.batch_size)

        logger.info(f"âœ… åƒæ•¸ç¶²æ ¼ç”Ÿæˆå®Œæˆï¼š{len(self.param_grid)} çµ„åƒæ•¸")
        logger.info(f"   æ‰¹æ¬¡è¨­ç½®ï¼š{self.total_batches} æ‰¹ x {self.batch_size} çµ„/æ‰¹")

    def generate_param_grid(self) -> List[Dict]:
        """
        ç”Ÿæˆåƒæ•¸ç¶²æ ¼ï¼ˆæ™ºèƒ½æ¡æ¨£ï¼‰

        Returns:
            åƒæ•¸åˆ—è¡¨
        """
        param_grid = []

        # éšæ®µ 1: ç²—ç•¥æ¡æ¨£ï¼ˆ55 çµ„ï¼‰- å¿«é€Ÿæ‰¾å‡ºå¤§è‡´å€é–“
        param_grid.extend(self._coarse_sampling())

        # éšæ®µ 2: ç²¾ç´°æ¡æ¨£ï¼ˆ175 çµ„ï¼‰- åœ¨æœ€ä½³å€é–“å…§ç´°åŒ–
        param_grid.extend(self._fine_sampling())

        # éšæ®µ 3: é©—è­‰æ¡æ¨£ï¼ˆ75 çµ„ï¼‰- é©—è­‰å‡è¨­
        param_grid.extend(self._validation_sampling())

        logger.info(f"  éšæ®µ 1 (ç²—ç•¥æ¡æ¨£): {len([p for p in param_grid if p.get('stage') == 'coarse'])} çµ„")
        logger.info(f"  éšæ®µ 2 (ç²¾ç´°æ¡æ¨£): {len([p for p in param_grid if p.get('stage') == 'fine'])} çµ„")
        logger.info(f"  éšæ®µ 3 (é©—è­‰æ¡æ¨£): {len([p for p in param_grid if p.get('stage') == 'validation'])} çµ„")

        return param_grid

    def _coarse_sampling(self) -> List[Dict]:
        """
        ç²—ç•¥æ¡æ¨£ï¼šå¿«é€Ÿæ‰¾å‡ºå¤§è‡´å€é–“

        Returns:
            ç²—ç•¥æ¡æ¨£åƒæ•¸åˆ—è¡¨
        """
        params_list = []

        # Temperature ä¸»å°æ¸¬è©¦
        logger.info("  ç”Ÿæˆ Temperature ä¸»å°æ¸¬è©¦...")
        for temp in [0.4, 0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]:
            params_list.append({
                'temperature': temp,
                'top_p': 0.9,
                'repetition_penalty': 1.05,
                'max_tokens': 4000,
                'stage': 'coarse',
                'focus': 'temperature'
            })

        # Top_P ä¸»å°æ¸¬è©¦
        logger.info("  ç”Ÿæˆ Top_P ä¸»å°æ¸¬è©¦...")
        for top_p in [0.8, 0.82, 0.85, 0.88, 0.9, 0.92, 0.95, 0.98]:
            params_list.append({
                'temperature': 0.7,
                'top_p': top_p,
                'repetition_penalty': 1.05,
                'max_tokens': 4000,
                'stage': 'coarse',
                'focus': 'top_p'
            })

        # Repetition Penalty ä¸»å°æ¸¬è©¦
        logger.info("  ç”Ÿæˆ Repetition Penalty ä¸»å°æ¸¬è©¦...")
        for penalty in [0.95, 1.0, 1.03, 1.05, 1.08, 1.1, 1.15, 1.2]:
            params_list.append({
                'temperature': 0.7,
                'top_p': 0.9,
                'repetition_penalty': penalty,
                'max_tokens': 4000,
                'stage': 'coarse',
                'focus': 'penalty'
            })

        # Max Tokens ä¸»å°æ¸¬è©¦
        logger.info("  ç”Ÿæˆ Max Tokens ä¸»å°æ¸¬è©¦...")
        for tokens in [3000, 3500, 4000, 4500, 5000, 5500, 6000]:
            params_list.append({
                'temperature': 0.7,
                'top_p': 0.9,
                'repetition_penalty': 1.05,
                'max_tokens': tokens,
                'stage': 'coarse',
                'focus': 'max_tokens'
            })

        # çµ„åˆæ¸¬è©¦ - Temperature x Top_P
        logger.info("  ç”Ÿæˆçµ„åˆæ¸¬è©¦ï¼ˆTemperature x Top_Pï¼‰...")
        for temp in [0.6, 0.7, 0.8]:
            for top_p in [0.85, 0.9, 0.95]:
                params_list.append({
                    'temperature': temp,
                    'top_p': top_p,
                    'repetition_penalty': 1.05,
                    'max_tokens': 4000,
                    'stage': 'coarse',
                    'focus': 'temp_x_topp'
                })

        # çµ„åˆæ¸¬è©¦ - Temperature x Penalty
        logger.info("  ç”Ÿæˆçµ„åˆæ¸¬è©¦ï¼ˆTemperature x Penaltyï¼‰...")
        for temp in [0.6, 0.7, 0.8]:
            for penalty in [1.0, 1.05, 1.1]:
                params_list.append({
                    'temperature': temp,
                    'top_p': 0.9,
                    'repetition_penalty': penalty,
                    'max_tokens': 4000,
                    'stage': 'coarse',
                    'focus': 'temp_x_penalty'
                })

        # æ¥µç«¯å€¼æ¸¬è©¦
        logger.info("  ç”Ÿæˆæ¥µç«¯å€¼æ¸¬è©¦...")
        extreme_params = [
            # è¶…ä¿å®ˆ
            {'temperature': 0.3, 'top_p': 0.8, 'repetition_penalty': 0.9, 'max_tokens': 3000},
            # è¶…æ¿€é€²
            {'temperature': 1.0, 'top_p': 0.99, 'repetition_penalty': 1.3, 'max_tokens': 7000},
            # æ¥µä½å‰µæ„
            {'temperature': 0.4, 'top_p': 0.8, 'repetition_penalty': 1.2, 'max_tokens': 4000},
            # æ¥µé«˜å‰µæ„
            {'temperature': 0.95, 'top_p': 0.98, 'repetition_penalty': 0.95, 'max_tokens': 5000},
        ]

        for params in extreme_params:
            params['stage'] = 'coarse'
            params['focus'] = 'extreme'
            params_list.append(params)

        return params_list

    def _fine_sampling(self) -> List[Dict]:
        """
        ç²¾ç´°æ¡æ¨£ï¼šåœ¨æœ€ä½³å€é–“å…§ç´°åŒ–

        Returns:
            ç²¾ç´°æ¡æ¨£åƒæ•¸åˆ—è¡¨
        """
        params_list = []

        # åŸºæ–¼åˆæ­¥çµæœï¼Œå‡è¨­æœ€ä½³å€é–“ç‚ºï¼š
        # Temperature: 0.65-0.75
        # Top_P: 0.88-0.92
        # Penalty: 1.03-1.08
        # Max_Tokens: 4000-5000

        logger.info("  ç”Ÿæˆç²¾ç´°æ¡æ¨£ï¼ˆTemperature ç´°åŒ–ï¼‰...")
        for temp in [0.65, 0.67, 0.69, 0.71, 0.73, 0.75]:
            for top_p in [0.88, 0.9, 0.92]:
                for penalty in [1.03, 1.05, 1.08]:
                    params_list.append({
                        'temperature': temp,
                        'top_p': top_p,
                        'repetition_penalty': penalty,
                        'max_tokens': 4000,
                        'stage': 'fine',
                        'focus': 'optimal_range'
                    })

        logger.info("  ç”Ÿæˆç²¾ç´°æ¡æ¨£ï¼ˆTop_P ç´°åŒ–ï¼‰...")
        for top_p in [0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93]:
            for penalty in [1.03, 1.05, 1.08]:
                params_list.append({
                    'temperature': 0.7,
                    'top_p': top_p,
                    'repetition_penalty': penalty,
                    'max_tokens': 4000,
                    'stage': 'fine',
                    'focus': 'topp_refined'
                })

        logger.info("  ç”Ÿæˆç²¾ç´°æ¡æ¨£ï¼ˆPenalty ç´°åŒ–ï¼‰...")
        for penalty in [1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09]:
            params_list.append({
                'temperature': 0.7,
                'top_p': 0.9,
                'repetition_penalty': penalty,
                'max_tokens': 4000,
                'stage': 'fine',
                'focus': 'penalty_refined'
            })

        logger.info("  ç”Ÿæˆç²¾ç´°æ¡æ¨£ï¼ˆMax_Tokens ç´°åŒ–ï¼‰...")
        for tokens in [3800, 4000, 4200, 4400, 4600, 4800, 5000]:
            params_list.append({
                'temperature': 0.7,
                'top_p': 0.9,
                'repetition_penalty': 1.05,
                'max_tokens': tokens,
                'stage': 'fine',
                'focus': 'tokens_refined'
            })

        # å››ç¶­çµ„åˆï¼ˆæœ€ä½³å€é–“å…§çš„å…¨çµ„åˆï¼‰
        logger.info("  ç”Ÿæˆç²¾ç´°æ¡æ¨£ï¼ˆå››ç¶­çµ„åˆï¼‰...")
        for temp in [0.67, 0.7, 0.73]:
            for top_p in [0.88, 0.9, 0.92]:
                for penalty in [1.03, 1.05, 1.08]:
                    for tokens in [4000, 4500, 5000]:
                        params_list.append({
                            'temperature': temp,
                            'top_p': top_p,
                            'repetition_penalty': penalty,
                            'max_tokens': tokens,
                            'stage': 'fine',
                            'focus': '4d_combination'
                        })

        return params_list

    def _validation_sampling(self) -> List[Dict]:
        """
        é©—è­‰æ¡æ¨£ï¼šé©—è­‰å‡è¨­

        Returns:
            é©—è­‰æ¡æ¨£åƒæ•¸åˆ—è¡¨
        """
        params_list = []

        # å‡è¨­ 1ï¼šæœ€ä½³åƒæ•¸é™„è¿‘é‡è¤‡æ¸¬è©¦ï¼ˆé©—è­‰ç©©å®šæ€§ï¼‰
        logger.info("  ç”Ÿæˆé©—è­‰æ¡æ¨£ï¼ˆç©©å®šæ€§æ¸¬è©¦ï¼‰...")
        best_params = {
            'temperature': 0.7,
            'top_p': 0.9,
            'repetition_penalty': 1.05,
            'max_tokens': 4000
        }

        for i in range(20):  # é‡è¤‡ 20 æ¬¡
            params = best_params.copy()
            params['stage'] = 'validation'
            params['focus'] = 'stability'
            params['repeat_id'] = i
            params_list.append(params)

        # å‡è¨­ 2ï¼šå¾®èª¿æ¸¬è©¦ï¼ˆæœ€ä½³åƒæ•¸å‘¨åœçš„å¾®å°è®ŠåŒ–ï¼‰
        logger.info("  ç”Ÿæˆé©—è­‰æ¡æ¨£ï¼ˆå¾®èª¿æ¸¬è©¦ï¼‰...")
        for temp_delta in [-0.02, -0.01, 0, 0.01, 0.02]:
            for topp_delta in [-0.01, 0, 0.01]:
                for penalty_delta in [-0.01, 0, 0.01]:
                    params_list.append({
                        'temperature': 0.7 + temp_delta,
                        'top_p': 0.9 + topp_delta,
                        'repetition_penalty': 1.05 + penalty_delta,
                        'max_tokens': 4000,
                        'stage': 'validation',
                        'focus': 'fine_tuning'
                    })

        # å‡è¨­ 3ï¼šå°æ¯”æ¸¬è©¦ï¼ˆèˆ‡ R1 æœ€ä½³åƒæ•¸å°æ¯”ï¼‰
        logger.info("  ç”Ÿæˆé©—è­‰æ¡æ¨£ï¼ˆR1 å°æ¯”ï¼‰...")
        r1_style_params = [
            {'temperature': 0.6, 'top_p': 0.95, 'repetition_penalty': 1.0, 'max_tokens': 3500},
            {'temperature': 0.65, 'top_p': 0.92, 'repetition_penalty': 1.02, 'max_tokens': 4000},
        ]

        for params in r1_style_params:
            for i in range(5):  # æ¯çµ„é‡è¤‡ 5 æ¬¡
                test_params = params.copy()
                test_params['stage'] = 'validation'
                test_params['focus'] = 'r1_comparison'
                test_params['repeat_id'] = i
                params_list.append(test_params)

        return params_list

    def load_checkpoint(self) -> Dict:
        """
        åŠ è¼‰æª¢æŸ¥é»

        Returns:
            æª¢æŸ¥é»æ•¸æ“š
        """
        if self.checkpoint_file.exists():
            with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            'completed_batches': [],
            'current_batch': None,
            'batch_results': {},
            'start_time': datetime.now().isoformat()
        }

    def save_checkpoint(self, checkpoint_data: Dict):
        """
        ä¿å­˜æª¢æŸ¥é»

        Args:
            checkpoint_data: æª¢æŸ¥é»æ•¸æ“š
        """
        with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)

    def test_single_param(self, params: Dict) -> Dict:
        """
        æ¸¬è©¦å–®çµ„åƒæ•¸

        Args:
            params: åƒæ•¸é…ç½®

        Returns:
            æ¸¬è©¦çµæœ
        """
        # æå–æ¸¬è©¦åƒæ•¸
        test_params = {
            'temperature': params['temperature'],
            'top_p': params['top_p'],
            'repetition_penalty': params['repetition_penalty'],
            'max_tokens': params['max_tokens']
        }

        # å‰µå»ºæ¸¬è©¦å™¨
        tester = GLM4ParamsTester(
            self.api_key,
            quick_mode=self.quick_mode,
            enable_ai_review=False,
            debug_mode=False
        )

        try:
            # åŸ·è¡Œæ¸¬è©¦
            outline, cost, score = tester.test_params(test_params)

            # è¿”å›çµæœ
            result = {
                'params': test_params,
                'stage': params.get('stage', 'unknown'),
                'focus': params.get('focus', 'unknown'),
                'score': score,
                'cost': cost,
                'outline_length': len(outline) if outline else 0,
                'timestamp': datetime.now().isoformat(),
                'success': True
            }

            # æ·»åŠ é‡è¤‡ IDï¼ˆå¦‚æœæœ‰ï¼‰
            if 'repeat_id' in params:
                result['repeat_id'] = params['repeat_id']

            return result

        except Exception as e:
            logger.error(f"æ¸¬è©¦å¤±æ•—: {e}")
            return {
                'params': test_params,
                'stage': params.get('stage', 'unknown'),
                'focus': params.get('focus', 'unknown'),
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'success': False
            }

    def run_batch(self, batch_num: int) -> List[Dict]:
        """
        åŸ·è¡Œå–®æ‰¹æ¸¬è©¦

        Args:
            batch_num: æ‰¹æ¬¡ç·¨è™Ÿ

        Returns:
            æ‰¹æ¬¡çµæœåˆ—è¡¨
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸš€ é–‹å§‹æ‰¹æ¬¡ {batch_num + 1}/{self.total_batches}")
        logger.info(f"{'='*60}\n")

        # åŠ è¼‰æª¢æŸ¥é»
        checkpoint = self.load_checkpoint()

        # æª¢æŸ¥æ˜¯å¦å·²å®Œæˆ
        if batch_num in checkpoint.get('completed_batches', []):
            logger.info(f"âœ… æ‰¹æ¬¡ {batch_num + 1} å·²å®Œæˆï¼Œè·³é")
            return checkpoint['batch_results'].get(str(batch_num), [])

        # ç²å–ç•¶å‰æ‰¹æ¬¡çš„åƒæ•¸
        start_idx = batch_num * self.batch_size
        end_idx = min(start_idx + self.batch_size, len(self.param_grid))
        batch_params = self.param_grid[start_idx:end_idx]

        logger.info(f"ğŸ“‹ æ‰¹æ¬¡åƒæ•¸æ•¸é‡: {len(batch_params)}")
        logger.info(f"ğŸ“ åƒæ•¸ç´¢å¼•ç¯„åœ: {start_idx} - {end_idx - 1}\n")

        results = []
        for i, params in enumerate(batch_params):
            logger.info(f"ğŸ”¬ æ¸¬è©¦ {i + 1}/{len(batch_params)} (ç¸½é€²åº¦: {start_idx + i + 1}/{len(self.param_grid)})")
            logger.info(f"   åƒæ•¸: T={params['temperature']}, P={params['top_p']}, Pen={params['repetition_penalty']}, Tok={params['max_tokens']}")
            logger.info(f"   éšæ®µ: {params.get('stage', 'unknown')}, ç„¦é»: {params.get('focus', 'unknown')}")

            try:
                result = self.test_single_param(params)
                results.append(result)

                if result['success']:
                    logger.info(f"   âœ… æˆåŠŸ - ç¸½åˆ†: {result['score']['total_score']:.0f}/120")
                else:
                    logger.info(f"   âŒ å¤±æ•— - {result.get('error', 'Unknown error')}")

                # æ¯ 10 å€‹æ¸¬è©¦ä¿å­˜ä¸€æ¬¡æª¢æŸ¥é»
                if (i + 1) % 10 == 0:
                    checkpoint['current_batch'] = batch_num
                    checkpoint['batch_results'][str(batch_num)] = results
                    self.save_checkpoint(checkpoint)
                    logger.info(f"   ğŸ’¾ æª¢æŸ¥é»å·²ä¿å­˜ ({i + 1}/{len(batch_params)})")

                # API å»¶é²ï¼ˆé¿å…éè¼‰ï¼‰
                delay = random.uniform(3, 5)
                logger.info(f"   â³ ç­‰å¾… {delay:.1f} ç§’...\n")
                time.sleep(delay)

            except Exception as e:
                logger.error(f"   âŒ æ¸¬è©¦ç•°å¸¸: {e}\n")
                continue

        # ä¿å­˜æ‰¹æ¬¡çµæœ
        batch_file = self.output_dir / f"batch_{batch_num:02d}_results.json"
        with open(batch_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        # æ›´æ–°æª¢æŸ¥é»
        checkpoint['completed_batches'].append(batch_num)
        checkpoint['batch_results'][str(batch_num)] = results
        checkpoint['current_batch'] = None
        self.save_checkpoint(checkpoint)

        # è¨ˆç®—æ‰¹æ¬¡çµ±è¨ˆ
        successful = sum(1 for r in results if r.get('success', False))
        failed = len(results) - successful

        logger.info(f"\n{'='*60}")
        logger.info(f"âœ… æ‰¹æ¬¡ {batch_num + 1} å®Œæˆ")
        logger.info(f"{'='*60}")
        logger.info(f"æˆåŠŸ: {successful}/{len(results)}")
        logger.info(f"å¤±æ•—: {failed}/{len(results)}")
        logger.info(f"çµæœå·²ä¿å­˜: {batch_file}\n")

        return results

    def run_all_batches(self):
        """åŸ·è¡Œæ‰€æœ‰æ‰¹æ¬¡"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ¯ é–‹å§‹è¶…å¤§è¦æ¨¡åƒæ•¸æ¸¬è©¦")
        logger.info("="*60)
        logger.info(f"ç¸½åƒæ•¸çµ„æ•¸: {len(self.param_grid)}")
        logger.info(f"æ‰¹æ¬¡æ•¸é‡: {self.total_batches}")
        logger.info(f"æ¯æ‰¹å¤§å°: {self.batch_size}")
        logger.info(f"å¿«é€Ÿæ¨¡å¼: {'æ˜¯' if self.quick_mode else 'å¦'}")
        logger.info(f"è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        logger.info("="*60 + "\n")

        start_time = time.time()

        for batch_num in range(self.total_batches):
            self.run_batch(batch_num)

            # æ‰¹æ¬¡é–“ä¼‘æ¯ï¼ˆæœ€å¾Œä¸€æ‰¹é™¤å¤–ï¼‰
            if batch_num < self.total_batches - 1:
                rest_time = 300  # 5 åˆ†é˜
                logger.info(f"â¸ï¸  æ‰¹æ¬¡é–“ä¼‘æ¯ {rest_time // 60} åˆ†é˜...")
                logger.info(f"   ä¸‹ä¸€æ‰¹æ¬¡å°‡æ–¼ {datetime.now().strftime('%H:%M:%S')} å¾Œé–‹å§‹\n")
                time.sleep(rest_time)

        # è¨ˆç®—ç¸½è€—æ™‚
        total_time = time.time() - start_time
        hours = int(total_time // 3600)
        minutes = int((total_time % 3600) // 60)
        seconds = int(total_time % 60)

        logger.info("\n" + "="*60)
        logger.info("ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡åŸ·è¡Œå®Œæˆï¼")
        logger.info("="*60)
        logger.info(f"ç¸½è€—æ™‚: {hours}å°æ™‚ {minutes}åˆ†é˜ {seconds}ç§’")
        logger.info(f"çµæœç›®éŒ„: {self.output_dir}")
        logger.info("="*60 + "\n")

        # ç”Ÿæˆå¿«é€Ÿæ‘˜è¦
        self.generate_quick_summary()

    def generate_quick_summary(self):
        """ç”Ÿæˆå¿«é€Ÿæ‘˜è¦"""
        logger.info("ğŸ“Š ç”Ÿæˆæ¸¬è©¦æ‘˜è¦...")

        # åŠ è¼‰æ‰€æœ‰æ‰¹æ¬¡çµæœ
        all_results = []
        for batch_num in range(self.total_batches):
            batch_file = self.output_dir / f"batch_{batch_num:02d}_results.json"
            if batch_file.exists():
                with open(batch_file, 'r', encoding='utf-8') as f:
                    all_results.extend(json.load(f))

        # è¨ˆç®—çµ±è¨ˆ
        total_tests = len(all_results)
        successful = sum(1 for r in all_results if r.get('success', False))
        failed = total_tests - successful

        if successful > 0:
            avg_score = sum(r['score']['total_score'] for r in all_results if r.get('success', False)) / successful
            max_score = max(r['score']['total_score'] for r in all_results if r.get('success', False))
            min_score = min(r['score']['total_score'] for r in all_results if r.get('success', False))
        else:
            avg_score = max_score = min_score = 0

        # ä¿å­˜æ‘˜è¦
        summary = {
            'total_tests': total_tests,
            'successful': successful,
            'failed': failed,
            'success_rate': successful / total_tests if total_tests > 0 else 0,
            'avg_score': avg_score,
            'max_score': max_score,
            'min_score': min_score,
            'timestamp': datetime.now().isoformat()
        }

        summary_file = self.output_dir / "quick_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        logger.info(f"\n{'='*60}")
        logger.info("ğŸ“ˆ æ¸¬è©¦æ‘˜è¦")
        logger.info(f"{'='*60}")
        logger.info(f"ç¸½æ¸¬è©¦æ•¸: {total_tests}")
        logger.info(f"æˆåŠŸ: {successful} ({successful/total_tests*100:.1f}%)")
        logger.info(f"å¤±æ•—: {failed} ({failed/total_tests*100:.1f}%)")
        logger.info(f"å¹³å‡åˆ†æ•¸: {avg_score:.1f}/120")
        logger.info(f"æœ€é«˜åˆ†æ•¸: {max_score:.1f}/120")
        logger.info(f"æœ€ä½åˆ†æ•¸: {min_score:.1f}/120")
        logger.info(f"{'='*60}\n")
        logger.info(f"æ‘˜è¦å·²ä¿å­˜: {summary_file}")
        logger.info(f"\nğŸ’¡ æç¤º: é‹è¡Œ 'python tests/analyze_mega_results.py' ç”Ÿæˆè©³ç´°åˆ†æå ±å‘Š\n")


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='GLM-4 è¶…å¤§è¦æ¨¡åƒæ•¸æ¸¬è©¦')

    parser.add_argument('--batch', type=int, help='åŸ·è¡ŒæŒ‡å®šæ‰¹æ¬¡ï¼ˆ0-11ï¼‰')
    parser.add_argument('--run-all', action='store_true', help='åŸ·è¡Œæ‰€æœ‰æ‰¹æ¬¡')
    parser.add_argument('--resume', action='store_true', help='å¾æª¢æŸ¥é»æ¢å¾©')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼ˆåƒ…ç”Ÿæˆå¤§ç¶±ï¼‰')
    parser.add_argument('--batch-size', type=int, default=50, help='æ¯æ‰¹æ¸¬è©¦æ•¸é‡ï¼ˆé»˜èª 50ï¼‰')

    args = parser.parse_args()

    # ç²å– API Key
    import os
    from dotenv import load_dotenv
    load_dotenv()
    api_key = os.getenv("SILICONFLOW_API_KEY")

    if not api_key:
        logger.error("âŒ æ‰¾ä¸åˆ° SILICONFLOW_API_KEY ç’°å¢ƒè®Šé‡")
        return

    # å‰µå»ºæ¸¬è©¦å™¨
    tester = MegaParamsTester(api_key, quick_mode=args.quick, batch_size=args.batch_size)

    if args.run_all:
        # åŸ·è¡Œæ‰€æœ‰æ‰¹æ¬¡
        tester.run_all_batches()
    elif args.resume:
        # å¾æª¢æŸ¥é»æ¢å¾©
        checkpoint = tester.load_checkpoint()
        completed = checkpoint.get('completed_batches', [])
        logger.info(f"å·²å®Œæˆæ‰¹æ¬¡: {completed}")

        for batch_num in range(tester.total_batches):
            if batch_num not in completed:
                logger.info(f"å¾æ‰¹æ¬¡ {batch_num + 1} æ¢å¾©...")
                tester.run_batch(batch_num)
    elif args.batch is not None:
        # åŸ·è¡ŒæŒ‡å®šæ‰¹æ¬¡
        if 0 <= args.batch < tester.total_batches:
            tester.run_batch(args.batch)
        else:
            logger.error(f"âŒ æ‰¹æ¬¡ç·¨è™Ÿç„¡æ•ˆ: {args.batch}ï¼ˆæœ‰æ•ˆç¯„åœ: 0-{tester.total_batches - 1}ï¼‰")
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
